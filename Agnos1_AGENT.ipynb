{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1116d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 199\u001b[0m\n\u001b[0;32m    196\u001b[0m     Data_analysis \u001b[38;5;241m=\u001b[39m Agent001(inp_query)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[43mAgent47\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 195\u001b[0m, in \u001b[0;36mAgent47\u001b[1;34m()\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAgent47\u001b[39m():\n\u001b[1;32m--> 195\u001b[0m     inp_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m     Data_analysis \u001b[38;5;241m=\u001b[39m Agent001(inp_query)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def local_var_list(local_var):\n",
    "    keys = local_var.keys()\n",
    "    keys_list = list(local_var)\n",
    "    keys_list.pop(0)\n",
    "    print(\"-------------------keys_list: \",keys_list)\n",
    "    return keys_list\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def execute(code):\n",
    "    try:\n",
    "        local_var = {}\n",
    "        res = exec(code, local_var)\n",
    "        return None, None, local_var  # No return value if code execution succeeds\n",
    "    except FileNotFoundError as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "    except pd.errors.ParserError as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "    except Exception as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def O_LLM(query):\n",
    "    #\n",
    "    data = {\n",
    "    \"model\": \"codellama:13b\",\n",
    "    \"prompt\": query,\n",
    "    \"stream\": False}\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", data=json.dumps(data))\n",
    "    data = json.loads(response.text)\n",
    "    answer = data['response']\n",
    "    print(answer)\n",
    "    return answer\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def Agent07(query):\n",
    "    answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "\n",
    "    code_to_execute = code\n",
    "    print(\"\\n\\ncode:\",code)\n",
    "    \n",
    "    result, error, local_var = execute(code_to_execute)\n",
    "    \n",
    "    print(\"\\n \\nEXECUTION OUTPUT:\")\n",
    "    if error:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Error:\", error)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Result:\", result)\n",
    "        \n",
    "    return result, error, code, local_var\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "df = pd.DataFrame()\n",
    "first_row_csv_string = \"\"\n",
    "\n",
    "def Agent01():\n",
    "    inp_query = input(\">\")\n",
    "    \n",
    "    #write a python program to read 'data.csv' and visualize 2 graphs\n",
    "    query = f\"\"\"\n",
    "consider yourself as an Artificial General Intelligence Assistant, where your the best in the world, and has so much self confidence in your code or response.\n",
    "And Now :{inp_query}\n",
    "Dont add any comments or explanations here, as this will be run in a program, where errors may occur.\"\"\" \n",
    "    #\n",
    "    print(\"\\nQuery: \\n\",query)\n",
    "    result, error, code, local_var = Agent07(query)\n",
    "    if error:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Error:\", error)\n",
    "        for i in range(5):\n",
    "            print(\"*****************************************************************************************\")\n",
    "            #\n",
    "            print(i)\n",
    "            if i == 70:\n",
    "                keys_list = local_var_list(local_var)\n",
    "                print(\"---------------INTERATION--------------\",i)\n",
    "                var_query = f\"\"\"\n",
    "    By checking my code and error which variable from 'Variables list' you want to read to debug the error?\n",
    "    Code: {code}\n",
    "\n",
    "    Error: {error}\n",
    "\n",
    "    Variables: {keys_list}\n",
    "\n",
    "    Disclaimer: You need to repond with exact variable names with no extra comments, code or text, as this will be executed in terminal and may cause errors.\n",
    "    \"\"\"\n",
    "                print(\"var_query: >>>>>>>>>> \",var_query)\n",
    "                Var_query_output = O_LLM(var_query)\n",
    "                print(\"Var_query_output\",Var_query_output)\n",
    "                \n",
    "                \n",
    "            #print(\"\\n\\nlocal_var:\\n\",local_var)\n",
    "            code = str(code)\n",
    "            print(\"\\n\\ncode:\\n\",code)\n",
    "            error = str(error)\n",
    "            print(\"\\n\\nerror:\\n\",error)\n",
    "            print(\"\\n\\ninp_query:\\n\",inp_query)\n",
    "            inp_query = str(inp_query)\n",
    "            \n",
    "            if i == 1:\n",
    "                df = local_var[\"df\"]\n",
    "                print(df)\n",
    "\n",
    "                first_row_csv_string = df.iloc[[0]].to_csv(index=False)\n",
    "                print(first_row_csv_string)\n",
    "                first_row_csv_string = str(first_row_csv_string)\n",
    "            try:\n",
    "                if i > 2:\n",
    "                    nxt_query = \"<user: \"+ inp_query +\">\" + \"\\n\\n\" + \"\\n\\n 1st row of dataframe df = \" + first_row_csv_string + \" >\"+ \"\\n\\n <Prompt> :By looking at the dataframe and columns answer the question, Disclaimer: You need to repond with exact code with no extra comments, code or text, as this will be executed in terminal and may cause errors.\"\n",
    "                    print(\"nxt_query: \\n\",nxt_query)\n",
    "                    result, error, code = Agent07(nxt_query)\n",
    "                    if result:\n",
    "                        print(\"result found: \",result)\n",
    "                        break\n",
    "                else:\n",
    "                    nxt_query = \"<user: \"+ inp_query +\">\" + \"\\n\\n\" + \"<bot: \\n\" +\"Code: \" + code + \"\\n\\n Error: \" + error + \"\\n\\n 1st row of dataframe df = \" + first_row_csv_string + \" >\"+ \"\\n\\n <Prompt> :By looking at the dataframe, you can change or modify and make the code work, Disclaimer: You need to repond with exact code with no extra comments, code or text, as this will be executed in terminal and may cause errors.\"\n",
    "                    result, error, code = Agent07(nxt_query)\n",
    "                    if result:\n",
    "                        print(\"result found: \",result)\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Result:\", result)\n",
    "        \n",
    "    return True\n",
    "\n",
    "def Agent47():\n",
    "    inp_query = input(\">\")\n",
    "    Data_analysis = Agent01(inp_query)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    Agent47()\n",
    "#------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21bccd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your search query: chat\n",
      "Title: Google Chat - Sign In | Google Workspace\n",
      "Link: https://chat.google.com/\n",
      "\n",
      "Title: ChatGPT\n",
      "Link: https://chat.openai.com/\n",
      "\n",
      "Title: Google Chat - Apps on Google Play\n",
      "Link: https://play.google.com/store/apps/details?id=com.google.android.apps.dynamite&hl=en_US&gl=US\n",
      "\n",
      "Title: r/chat\n",
      "Link: https://www.reddit.com/r/chat/\n",
      "\n",
      "Title: Chat Definition & Meaning\n",
      "Link: https://www.merriam-webster.com/dictionary/chat\n",
      "\n",
      "Title: CHAT | English meaning - Cambridge Dictionary\n",
      "Link: https://dictionary.cambridge.org/dictionary/english/chat\n",
      "\n",
      "Title: Online chat\n",
      "Link: https://en.wikipedia.org/wiki/Online_chat\n",
      "\n",
      "Title: Google Chat Community\n",
      "Link: https://support.google.com/chat/community?hl=en\n",
      "\n",
      "Title: Google Chat: Messaging and Team Collaboration\n",
      "Link: https://workspace.google.com/products/chat/\n",
      "\n",
      "Title: Google Chat on the App Store\n",
      "Link: https://apps.apple.com/us/app/google-chat/id1163852619\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"h3\"}\n  (Session info: chrome-headless-shell=121.0.6167.140); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61BB77012+3522402]\n\t(No symbol) [0x00007FF61B798352]\n\t(No symbol) [0x00007FF61B645ABB]\n\t(No symbol) [0x00007FF61B68BF0E]\n\t(No symbol) [0x00007FF61B68C08C]\n\t(No symbol) [0x00007FF61B6812AC]\n\t(No symbol) [0x00007FF61B6AF09F]\n\t(No symbol) [0x00007FF61B68120A]\n\t(No symbol) [0x00007FF61B6AF270]\n\t(No symbol) [0x00007FF61B6CBDA3]\n\t(No symbol) [0x00007FF61B6AEE03]\n\t(No symbol) [0x00007FF61B67F4D4]\n\t(No symbol) [0x00007FF61B6805F1]\n\tGetHandleVerifier [0x00007FF61BBA9B9D+3730157]\n\tGetHandleVerifier [0x00007FF61BBFF02D+4079485]\n\tGetHandleVerifier [0x00007FF61BBF75D3+4048163]\n\tGetHandleVerifier [0x00007FF61B8CA649+718233]\n\t(No symbol) [0x00007FF61B7A4A3F]\n\t(No symbol) [0x00007FF61B79FA94]\n\t(No symbol) [0x00007FF61B79FBC2]\n\t(No symbol) [0x00007FF61B78F2E4]\n\tBaseThreadInitThunk [0x00007FFF49B67344+20]\n\tRtlUserThreadStart [0x00007FFF49FA26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     33\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your search query: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[43msearch_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36msearch_google\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     22\u001b[0m search_results \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.g\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[1;32m---> 24\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     25\u001b[0m     link \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\OpenAI_Langchain\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"h3\"}\n  (Session info: chrome-headless-shell=121.0.6167.140); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF61BB77012+3522402]\n\t(No symbol) [0x00007FF61B798352]\n\t(No symbol) [0x00007FF61B645ABB]\n\t(No symbol) [0x00007FF61B68BF0E]\n\t(No symbol) [0x00007FF61B68C08C]\n\t(No symbol) [0x00007FF61B6812AC]\n\t(No symbol) [0x00007FF61B6AF09F]\n\t(No symbol) [0x00007FF61B68120A]\n\t(No symbol) [0x00007FF61B6AF270]\n\t(No symbol) [0x00007FF61B6CBDA3]\n\t(No symbol) [0x00007FF61B6AEE03]\n\t(No symbol) [0x00007FF61B67F4D4]\n\t(No symbol) [0x00007FF61B6805F1]\n\tGetHandleVerifier [0x00007FF61BBA9B9D+3730157]\n\tGetHandleVerifier [0x00007FF61BBFF02D+4079485]\n\tGetHandleVerifier [0x00007FF61BBF75D3+4048163]\n\tGetHandleVerifier [0x00007FF61B8CA649+718233]\n\t(No symbol) [0x00007FF61B7A4A3F]\n\t(No symbol) [0x00007FF61B79FA94]\n\t(No symbol) [0x00007FF61B79FBC2]\n\t(No symbol) [0x00007FF61B78F2E4]\n\tBaseThreadInitThunk [0x00007FFF49B67344+20]\n\tRtlUserThreadStart [0x00007FFF49FA26B1+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def search_google(query):\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "    # Initialize Chrome driver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Navigate to Google\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    # Find the search box and input the query\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "    search_box.send_keys(query)\n",
    "    search_box.submit()\n",
    "\n",
    "    # Find and print search results\n",
    "    search_results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "    for result in search_results:\n",
    "        title = result.find_element(By.CSS_SELECTOR, \"h3\").text\n",
    "        link = result.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Link: {link}\")\n",
    "        print()\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "query = input(\"Enter your search query: \")\n",
    "search_google(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e839030c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aabd8349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent02 Reporting\n",
      "Report sent Over! -Agent02\n"
     ]
    }
   ],
   "source": [
    "#BROWSER!\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#URL search-------------------------------------------------------------------------------------------------------\n",
    "def url_browser(url):\n",
    "    print(\"Agent url_browser reporting\")\n",
    "    try:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\") \n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(url)\n",
    "\n",
    "        elements = driver.find_elements(By.XPATH,\"//*[text()]\")\n",
    "        formatted_text = \"\"\n",
    "        for element in elements:\n",
    "            text = element.text.strip()\n",
    "            if text:\n",
    "                formatted_text += text + \"\\n\"\n",
    "\n",
    "        driver.quit()\n",
    "        print(\"Report sent -Over 'url_browser'\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception Occured, may be AI access Denied\",e)\n",
    "        formatted_text = \"Access Denied, Exception occured\"\n",
    "    return formatted_text\n",
    "\n",
    "#Browser search-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def description_filter(text):\n",
    "    lines = text.split('\\n')\n",
    "    source = lines[1]\n",
    "    lines[1] = f'from {source}'\n",
    "    del lines[2]\n",
    "    modified_text = '\\n'.join(lines)\n",
    "    return modified_text\n",
    "\n",
    "\n",
    "\n",
    "def Agent02(search_key):\n",
    "    print(\"Agent02 Reporting\")\n",
    "    ordered_urls = OrderedDict()\n",
    "    description_list = []\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    search_text = \"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\"\n",
    "    search_list = \"/html/body/div[5]/div/div[12]/div/div[2]/div[2]/div/div\"\n",
    "\n",
    "    search_text_button = driver.find_element(By.XPATH, search_text)\n",
    "    search_text_button.send_keys(search_key)\n",
    "    search_text_button.send_keys(Keys.ENTER)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    try:\n",
    "        search_list_tag = driver.find_element(By.XPATH, search_list)\n",
    "    except Exception as e:\n",
    "        time.sleep(0.5)\n",
    "        search_list_tag = driver.find_element(By.XPATH, search_list)\n",
    "\n",
    "\n",
    "    child_div_elements = search_list_tag.find_elements(By.XPATH, \"./div\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    for div in child_div_elements:\n",
    "        #description_list.append(div.text)\n",
    "        ref_d = description_filter(div.text)\n",
    "        description_list.append(ref_d)\n",
    "        html_content = div.get_attribute('outerHTML')\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        for child in soup.find_all('div', recursive=True):\n",
    "            for inner_child in child.find_all('div', recursive=True):\n",
    "                for span in inner_child.find_all('span', recursive=True):\n",
    "                    for a_tag in span.find_all('a'):\n",
    "                        href = a_tag.get('href')\n",
    "                        if href:\n",
    "                            if href not in ordered_urls:\n",
    "                                ordered_urls[href] = True\n",
    "    url_dict = dict(ordered_urls)\n",
    "    print(\"Report sent Over! -Agent02\")\n",
    "    return url_dict, description_list\n",
    "#Browser search-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "url_dict, description_list = Agent02(\"python llm code\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7486d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccd2da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/onlyphantom/llm-python\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://medium.com/@cpaggen/minimal-python-code-for-local-llm-inference-112782af509a\n",
      "Agent url_browser reporting\n",
      "Exception Occured, may be AI access Denied Message: stale element reference: stale element not found\n",
      "  (Session info: chrome-headless-shell=121.0.6167.140); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF657E87012+3522402]\n",
      "\t(No symbol) [0x00007FF657AA8352]\n",
      "\t(No symbol) [0x00007FF657955ABB]\n",
      "\t(No symbol) [0x00007FF65795AD09]\n",
      "\t(No symbol) [0x00007FF65795D110]\n",
      "\t(No symbol) [0x00007FF65795D1D0]\n",
      "\t(No symbol) [0x00007FF6579971FB]\n",
      "\t(No symbol) [0x00007FF6579BF05A]\n",
      "\t(No symbol) [0x00007FF65799120A]\n",
      "\t(No symbol) [0x00007FF6579BF270]\n",
      "\t(No symbol) [0x00007FF6579DBDA3]\n",
      "\t(No symbol) [0x00007FF6579BEE03]\n",
      "\t(No symbol) [0x00007FF65798F4D4]\n",
      "\t(No symbol) [0x00007FF6579905F1]\n",
      "\tGetHandleVerifier [0x00007FF657EB9B9D+3730157]\n",
      "\tGetHandleVerifier [0x00007FF657F0F02D+4079485]\n",
      "\tGetHandleVerifier [0x00007FF657F075D3+4048163]\n",
      "\tGetHandleVerifier [0x00007FF657BDA649+718233]\n",
      "\t(No symbol) [0x00007FF657AB4A3F]\n",
      "\t(No symbol) [0x00007FF657AAFA94]\n",
      "\t(No symbol) [0x00007FF657AAFBC2]\n",
      "\t(No symbol) [0x00007FF657A9F2E4]\n",
      "\tBaseThreadInitThunk [0x00007FFF49B67344+20]\n",
      "\tRtlUserThreadStart [0x00007FFF49FA26B1+33]\n",
      "\n",
      "https://github.com/ModelTC/lightllm\n",
      "Agent url_browser reporting\n",
      "Exception Occured, may be AI access Denied Message: no such element: No node with given id found\n",
      "  (Session info: chrome-headless-shell=121.0.6167.140); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF657E87012+3522402]\n",
      "\t(No symbol) [0x00007FF657AA8352]\n",
      "\t(No symbol) [0x00007FF657955ABB]\n",
      "\t(No symbol) [0x00007FF657943554]\n",
      "\t(No symbol) [0x00007FF6579413D1]\n",
      "\t(No symbol) [0x00007FF657941E3F]\n",
      "\t(No symbol) [0x00007FF657941D70]\n",
      "\t(No symbol) [0x00007FF6579653A1]\n",
      "\t(No symbol) [0x00007FF65795B8F7]\n",
      "\t(No symbol) [0x00007FF657959CE0]\n",
      "\t(No symbol) [0x00007FF65795D110]\n",
      "\t(No symbol) [0x00007FF65795D1D0]\n",
      "\t(No symbol) [0x00007FF6579971FB]\n",
      "\t(No symbol) [0x00007FF6579BF05A]\n",
      "\t(No symbol) [0x00007FF65799120A]\n",
      "\t(No symbol) [0x00007FF6579BF270]\n",
      "\t(No symbol) [0x00007FF6579DBDA3]\n",
      "\t(No symbol) [0x00007FF6579BEE03]\n",
      "\t(No symbol) [0x00007FF65798F4D4]\n",
      "\t(No symbol) [0x00007FF6579905F1]\n",
      "\tGetHandleVerifier [0x00007FF657EB9B9D+3730157]\n",
      "\tGetHandleVerifier [0x00007FF657F0F02D+4079485]\n",
      "\tGetHandleVerifier [0x00007FF657F075D3+4048163]\n",
      "\tGetHandleVerifier [0x00007FF657BDA649+718233]\n",
      "\t(No symbol) [0x00007FF657AB4A3F]\n",
      "\t(No symbol) [0x00007FF657AAFA94]\n",
      "\t(No symbol) [0x00007FF657AAFBC2]\n",
      "\t(No symbol) [0x00007FF657A9F2E4]\n",
      "\tBaseThreadInitThunk [0x00007FFF49B67344+20]\n",
      "\tRtlUserThreadStart [0x00007FFF49FA26B1+33]\n",
      "\n",
      "https://huggingface.co/blog/Alex1337/create-a-web-interface-for-your-llm-in-python\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://code.pieces.app/blog/best-llm-for-coding-cloud-vs-local#:~:text=The%20term%20'Large'%20in%20Large,significantly%20larger%20number%20of%20parameters.\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://www.analyticsvidhya.com/blog/2023/09/llms-for-code/#:~:text=A%20Large%20Language%20Model%20(LLM,understand%20and%20generate%20computer%20code.\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://www.scribbledata.io/blog/the-top-llms-for-code-generation-2024-edition/#:~:text=StarCoder%20is%20a%20state%2Dof,documentation%20and%20Jupyter%20programming%20notebooks.\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://ai.meta.com/blog/code-llama-large-language-model-coding/\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://www.reddit.com/r/LocalLLaMA/comments/18bxgvu/best_text_to_python_code_llm/\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://rushabhdoshi.com/projects/2023-05-22-announcing-llm-code/\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://python.langchain.com/docs/use_cases/code_understanding\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n",
      "https://pypi.org/project/llm-code/\n",
      "Agent url_browser reporting\n",
      "Report sent -Over 'url_browser'\n"
     ]
    }
   ],
   "source": [
    "webpage_text_list = []\n",
    "for i in url_dict:\n",
    "    print(i)\n",
    "    webpage_text = url_browser(i)\n",
    "    webpage_text_list.append(webpage_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12d3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c16a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1131bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://www.linkedin.com/in/akhil-songa-agnos\"\n",
    "\n",
    "def url_browser(url):\n",
    "    chrome_options = Options()\n",
    "    #chrome_options.add_argument(\"--headless\") \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "\n",
    "url_browser(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "657d77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip to content\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Change Language\n",
      "Machine Learning Tutorial\n",
      "Data Analysis Tutorial\n",
      "Python - Data visualization tutorial\n",
      "NumPy\n",
      "Pandas\n",
      "OpenCV\n",
      "R\n",
      "Machine Learning Projects\n",
      "Machine Learning Interview Questions\n",
      "Machine Learning Mathematics\n",
      "Deep Learning Tutorial\n",
      "Deep Learning Project\n",
      "Deep Learning Interview Questions\n",
      "Computer Vision Tutorial\n",
      "Computer Vision Projects\n",
      "NLP\n",
      "NLP Project\n",
      "NLP Interview Questions\n",
      "Statistics with Python\n",
      "100 Days of Machine Learning\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy\n",
      "Got It !\n",
      "Skip to content\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Change Language\n",
      "Machine Learning Tutorial\n",
      "Data Analysis Tutorial\n",
      "Python - Data visualization tutorial\n",
      "NumPy\n",
      "Pandas\n",
      "OpenCV\n",
      "R\n",
      "Machine Learning Projects\n",
      "Machine Learning Interview Questions\n",
      "Machine Learning Mathematics\n",
      "Deep Learning Tutorial\n",
      "Deep Learning Project\n",
      "Deep Learning Interview Questions\n",
      "Computer Vision Tutorial\n",
      "Computer Vision Projects\n",
      "NLP\n",
      "NLP Project\n",
      "NLP Interview Questions\n",
      "Statistics with Python\n",
      "100 Days of Machine Learning\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy\n",
      "Got It !\n",
      "Skip to content\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Change Language\n",
      "Skip to content\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Change Language\n",
      "Skip to content\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Change Language\n",
      "Contests\n",
      "GBlog\n",
      "Puzzles\n",
      "What's New ?\n",
      "Contests\n",
      "Contests\n",
      "Contests\n",
      "GBlog\n",
      "GBlog\n",
      "Puzzles\n",
      "Puzzles\n",
      "What's New ?\n",
      "What's New ?\n",
      "Change Language\n",
      "Change Language\n",
      "Change Language\n",
      "Machine Learning Tutorial\n",
      "Data Analysis Tutorial\n",
      "Python - Data visualization tutorial\n",
      "NumPy\n",
      "Pandas\n",
      "OpenCV\n",
      "R\n",
      "Machine Learning Projects\n",
      "Machine Learning Interview Questions\n",
      "Machine Learning Mathematics\n",
      "Deep Learning Tutorial\n",
      "Deep Learning Project\n",
      "Deep Learning Interview Questions\n",
      "Computer Vision Tutorial\n",
      "Computer Vision Projects\n",
      "NLP\n",
      "NLP Project\n",
      "NLP Interview Questions\n",
      "Statistics with Python\n",
      "100 Days of Machine Learning\n",
      "Machine Learning Tutorial\n",
      "Data Analysis Tutorial\n",
      "Python - Data visualization tutorial\n",
      "NumPy\n",
      "Pandas\n",
      "OpenCV\n",
      "R\n",
      "Machine Learning Projects\n",
      "Machine Learning Interview Questions\n",
      "Machine Learning Mathematics\n",
      "Deep Learning Tutorial\n",
      "Deep Learning Project\n",
      "Deep Learning Interview Questions\n",
      "Computer Vision Tutorial\n",
      "Computer Vision Projects\n",
      "NLP\n",
      "NLP Project\n",
      "NLP Interview Questions\n",
      "Statistics with Python\n",
      "100 Days of Machine Learning\n",
      "Machine Learning Tutorial\n",
      "Data Analysis Tutorial\n",
      "Python - Data visualization tutorial\n",
      "NumPy\n",
      "Pandas\n",
      "OpenCV\n",
      "R\n",
      "Machine Learning Projects\n",
      "Machine Learning Interview Questions\n",
      "Machine Learning Mathematics\n",
      "Deep Learning Tutorial\n",
      "Deep Learning Project\n",
      "Deep Learning Interview Questions\n",
      "Computer Vision Tutorial\n",
      "Computer Vision Projects\n",
      "NLP\n",
      "NLP Project\n",
      "NLP Interview Questions\n",
      "Statistics with Python\n",
      "100 Days of Machine Learning\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "DeepAR Forecasting Algorithm\n",
      "Vanishing and Exploding Gradients Problems in Deep Learning\n",
      "Sudoku Solver using TensorFlow\n",
      "Convolutional Variational Autoencoder in Tensorflow\n",
      "Iterative Dichotomiser 3 (ID3) Algorithm From Scratch\n",
      "Dirichlet Process Mixture Models (DPMMs)\n",
      "Deep Boltzmann Machines (DBMs) in Deep Learning\n",
      "Multioutput Regression in Machine Learning\n",
      "Ball Tree and KD Tree Algorithms\n",
      "Stochastic Gradient Descent Classifier\n",
      "Understanding PyTorch Learning Rate Scheduling\n",
      "Gaussian Process Regression (GPR)\n",
      "Seasonal Adjustment and Differencing in Time Series\n",
      "Understanding Gradient Clipping\n",
      "Complete Guide To SARIMAX in Python\n",
      "Understanding the Moving average (MA) in Time Series Data\n",
      "Optimization Rule in Deep Neural Networks\n",
      "How Does PyTorch Backprop Through Argmax?\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Video Generation using Python\n",
      "Video Generation using Python\n",
      "Video Generation using Python\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "\n",
      "\n",
      "Importing required libraries\n",
      "Now we will import all required Python libraries like OS, NumPy, Matplotlib, ImageIO etc.\n",
      "THIS Will Make You RICH! | Make Money Sitting at Home | GeeksforGeeks\n",
      "06:10\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this data. Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model   \n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any source image and driving video to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "In the vast landscape of multimedia technology, the art of video generation stands as a fascinating and innovative endeavor. It involves the dynamic synthesis of visual elements, breathing life into static images through intricate algorithms and models. Video generation has become an integral part of various domains, transcending mere entertainment and permeating fields like marketing, education, and virtual reality. In this article, we delve into the realm of video generation using Python, exploring the mechanisms that bring still images to vibrant motion. In this article, we will discuss how generate videos using Python programming language.\n",
      "Video generation techniques\n",
      "There are two most common video generation techniques which are listed below:\n",
      "First Order Motion Model: The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation: Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "First Order Motion Model:\n",
      "The First Order Motion Model stands at the forefront of video generation techniques, orchestrating a seamless blend of source images and driving videos. By leveraging key-point detection, this model dissects and maps the intricate movements from driving videos onto static source images. The result is a captivating synthesis, where inanimate images come alive with the dynamic rhythm of the accompanying video.\n",
      "Dynamic Pixel Transformation:\n",
      "Video generation involves a meticulous transformation of pixels, choreographed by complex algorithms that decode motion patterns. Through pixel-level transformations, the algorithms animate each frame, creating a coherent flow that mimics the motion of the driving video. By understanding this dynamic pixel transformation unveils the technical brilliance behind the creation of lifelike and fluid videos.\n",
      "Video Generation Step-by-step implementation\n",
      "Installing required modules\n",
      "At first, we will install all required python modules to our runtime.\n",
      "!pip install ffmpeg\n",
      "!pip install imageio-ffmpeg\n",
      "!git clone https://github.com/rkuo2000/first-order-model\n",
      "Importing required libraries\n",
      "Now we will import all required\n",
      "Python\n",
      "libraries like\n",
      "OS\n",
      ",\n",
      "NumPy\n",
      ",\n",
      "Matplotlib\n",
      ",\n",
      "ImageIO\n",
      "etc.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "Python3\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "os.chdir('first-order-model')\n",
      "import imageio\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from IPython.display import HTML\n",
      "from demo import make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "import os\n",
      "import\n",
      "os\n",
      "os.chdir(\n",
      "'first-order-model'\n",
      ")\n",
      "import imageio\n",
      "import\n",
      "imageio\n",
      "import numpy as np\n",
      "import\n",
      "numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import\n",
      "matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "import\n",
      "matplotlib.animation as animation\n",
      "from skimage.transform import resize\n",
      "from\n",
      "skimage.transform\n",
      "import\n",
      "resize\n",
      "from IPython.display import HTML\n",
      "from\n",
      "IPython.display\n",
      "import\n",
      "HTML\n",
      "from demo import make_animation\n",
      "from\n",
      "demo\n",
      "import\n",
      "make_animation\n",
      "from skimage import img_as_ubyte\n",
      "from\n",
      "skimage\n",
      "import\n",
      "img_as_ubyte\n",
      "from demo import load_checkpoints\n",
      "from\n",
      "demo\n",
      "import\n",
      "load_checkpoints\n",
      "Dataset loading\n",
      "As per generating video we will download this\n",
      "data\n",
      ". Then we will unzip it for further use.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "Python3\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "# Unzip the downloaded dataset\n",
      "!unzip -q first-order-motion-model.zip -d /content/first-order-motion-model\n",
      "!unzip\n",
      "-\n",
      "q first\n",
      "-\n",
      "order\n",
      "-\n",
      "motion\n",
      "-\n",
      "model.\n",
      "zip\n",
      "-\n",
      "d\n",
      "/\n",
      "content\n",
      "/\n",
      "first\n",
      "-\n",
      "order\n",
      "-\n",
      "motion\n",
      "-\n",
      "model\n",
      "Display function\n",
      "As we are generating video so we will to define a display function to visualize it. We will define a small function which will take source image and driving video then plot the generated video along with them so that we can cross check that how much accurate the video was generated.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "Python3\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "    fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "      ims=[]\n",
      "    for i in range(len(driving)):\n",
      "        cols=\n",
      "        cols.append(driving[i])\n",
      "        if generated is not None:\n",
      "            cols.append(generated[i])\n",
      "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "        plt.axis('off')\n",
      "        ims.append([im])\n",
      "    ani=animation.ArtistAnimation(fig,ims,interval=50,repeat_delay=1000)\n",
      "      plt.close()\n",
      "    return ani\n",
      "def display(source,driving,generated=None):\n",
      "def\n",
      "display(source,driving,generated\n",
      "=\n",
      "None\n",
      "):\n",
      "fig=plt.figure(figsize=(8+4*(generated is not None),6))\n",
      "fig\n",
      "=\n",
      "plt.figure(figsize\n",
      "=\n",
      "(\n",
      "8\n",
      "+\n",
      "4\n",
      "*\n",
      "(generated\n",
      "is\n",
      "not\n",
      "None\n",
      "),\n",
      "6\n",
      "))\n",
      "ims\n",
      "=\n",
      "[]\n",
      "for i in range(len(driving)):\n",
      "for\n",
      "i\n",
      "in\n",
      "range\n",
      "(\n",
      "len\n",
      "(driving)):\n",
      "cols\n",
      "=\n",
      "cols.append(driving[i])\n",
      "if generated is not None:\n",
      "if\n",
      "generated\n",
      "is\n",
      "not\n",
      "None\n",
      ":\n",
      "cols.append(generated[i])\n",
      "im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
      "im\n",
      "=\n",
      "plt.imshow(np.concatenate(cols, axis\n",
      "=\n",
      "1\n",
      "), animated\n",
      "=\n",
      "True\n",
      ")\n",
      "plt.axis(\n",
      "'off'\n",
      ")\n",
      "ims.append([im])\n",
      "ani\n",
      "=\n",
      "animation.ArtistAnimation(fig,ims,interval\n",
      "=\n",
      "50\n",
      ",repeat_delay\n",
      "=\n",
      "1000\n",
      ")\n",
      "plt.close()\n",
      "return ani\n",
      "return\n",
      "ani\n",
      "Model training\n",
      "Now we will load a pretrained first order motion model. Then we will pass any\n",
      "source image\n",
      "and\n",
      "driving video\n",
      "to generate new video. Finally, we will save it to our desired location.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "Python3\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "                            checkpoint_path='first-order-motion-model/vox-cpk.pth.tar')\n",
      "source_image=imageio.v2.imread('Ariana.jpg')\n",
      "driving_video=imageio.mimread('Leonardo.mp4')\n",
      "  #resize\n",
      "source_image=resize(source_image,(256,256))[...,:3]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "  predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "  imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml',\n",
      "generator, kp_detector\n",
      "=\n",
      "load_checkpoints(config_path\n",
      "=\n",
      "'config/vox-256.yaml'\n",
      ",\n",
      "checkpoint_path\n",
      "=\n",
      "'first-order-motion-model/vox-cpk.pth.tar'\n",
      ")\n",
      "source_image\n",
      "=\n",
      "imageio.v2.imread(\n",
      "'Ariana.jpg'\n",
      ")\n",
      "driving_video\n",
      "=\n",
      "imageio.mimread(\n",
      "'Leonardo.mp4'\n",
      ")\n",
      "#resize\n",
      "source_image\n",
      "=\n",
      "resize(source_image,(\n",
      "256\n",
      ",\n",
      "256\n",
      "))[...,:\n",
      "3\n",
      "]\n",
      "driving_video=[resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
      "driving_video\n",
      "=\n",
      "[resize(frame, (\n",
      "256\n",
      ",\n",
      "256\n",
      "))[..., :\n",
      "3\n",
      "]\n",
      "for\n",
      "frame\n",
      "in\n",
      "driving_video]\n",
      "predictions=make_animation(source_image,driving_video,generator,kp_detector, relative=True )\n",
      "predictions\n",
      "=\n",
      "make_animation(source_image,driving_video,generator,kp_detector, relative\n",
      "=\n",
      "True\n",
      ")\n",
      "imageio.mimsave('generated_video.mp4', [img_as_ubyte(frame) for frame in predictions]) # generated video saving loaction\n",
      "imageio.mimsave(\n",
      "'generated_video.mp4'\n",
      ", [img_as_ubyte(frame)\n",
      "for\n",
      "frame\n",
      "in\n",
      "predictions])\n",
      "# generated video saving loaction\n",
      "Visualizing the generated video with input\n",
      "Now we will call our display function to visualize the generated video with its inputs to understand the versability of the generated video.\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Python3\n",
      "\n",
      "\n",
      "\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Python3\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "# visulaizing video with inputs\n",
      "HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
      "Output:\n",
      "generated video with inputs\n",
      "So, in this output we have displayed the generated video (right most) with the input image (left most) and the driving video (middle one). However, you can also visualize and download the raw-only generated video (MP4 format) from the saved path.\n",
      "Applications of video generation\n",
      "Some of the real-world applications of video generation discussed below:\n",
      "Educational Content Creation: Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement: Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality: In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging: Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "Educational Content Creation:\n",
      "Video generation finds utility in education, where it breathes life into educational content by adding motion to static visuals. Complex concepts can be conveyed with greater clarity as images come alive, providing a more engaging learning experience.\n",
      "Marketing and Advertisement:\n",
      "Dynamic advertisements come to life through video generation which offers marketers a powerful tool to engage audiences with visually compelling content.\n",
      "Virtual Reality:\n",
      "In the realm of virtual reality, video generation enhances the realism of simulated environments by infusing them with dynamic motion to make virtual worlds more immersive as static images transform into vibrant, moving elements, enriching the user experience.\n",
      "Scientific and Medical Imaging:\n",
      "Beyond the creative realms, video generation contributes to scientific simulations and medical imaging by facilitating the dynamic representation of data. Simulations like molecular dynamics, gain a visual dimension, aiding researchers and educators in conveying intricate concepts.\n",
      "Here's a complete roadmap for you to become a developer: Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs And why go anywhere else when our DSA to Development: Coding Guide helps you do this in a single program!\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "Learn DSA -> Master Frontend/Backend/Full Stack -> Build Projects -> Keep Applying to Jobs\n",
      "DSA to Development: Coding Guide\n",
      "Apply now to our DSA to Development Program and our counsellors will connect with you for further guidance & support.\n",
      "DSA to Development Program\n",
      "Last Updated : 06 Feb, 2024\n",
      "1\n",
      "Last Updated : 06 Feb, 2024\n",
      "Last Updated :\n",
      "06 Feb, 2024\n",
      "1\n",
      "1\n",
      "1\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Previous\n",
      "Previous\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Orthogonal Matching Pursuit (OMP) using Sklearn\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Next\n",
      "Next\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Fine Tuning Large Language Model (LLM)\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Share your thoughts in the comments\n",
      "Share your thoughts in the comments\n",
      "Add Your Comment\n",
      "Add Your Comment\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "Similar Reads\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Avengers Endgame and Deep learning | Image Caption Generation using the Avengers EndGames Characters\n",
      "Random number generation using TensorFlow\n",
      "Random number generation using TensorFlow\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "Visualization and Prediction of Crop Production data using Python\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "ML | Natural Language Processing using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Prediction of Wine type using Deep Learning\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Implementing Deep Q-Learning using Tensorflow\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Human Activity Recognition - Using Deep Learning Model\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Image Caption Generator using Deep Learning on Flickr8K dataset\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Age Detection using Deep Learning in OpenCV\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "Lung Cancer Detection using Convolutional Neural Network (CNN)\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "susmit_sekhar_bhakta\n",
      "susmit_sekhar_bhakta\n",
      "susmit_sekhar_bhakta\n",
      "susmit_sekhar_bhakta\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Article Tags :\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Computer Vision Projects\n",
      "Computer Vision Projects\n",
      "Machine Learning\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Deep Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Practice Tags :\n",
      "Machine Learning\n",
      "Machine Learning\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "Trending in News\n",
      "View More\n",
      "Trending in News\n",
      "View More\n",
      "10 YouTube Alternatives to Stream Music Online in 2024\n",
      "12 Best Paint 3D Alternatives in 2024\n",
      "10 Best Pixlr Alternatives for Android in 2024 [Free + Paid]\n",
      "Bougie Definition and Usage Examples\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "30 OOPs Interview Questions and Answers (2024)\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "A-143, 9th Floor, Sovereign Corporate Tower, Sector-136, Noida, Uttar Pradesh - 201305\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "Company\n",
      "About Us\n",
      "Legal\n",
      "Careers\n",
      "In Media\n",
      "Contact Us\n",
      "Advertise with us\n",
      "GFG Corporate Solution\n",
      "Placement Training Program\n",
      "Explore\n",
      "Hack-A-Thons\n",
      "GfG Weekly Contest\n",
      "DSA in JAVA/C++\n",
      "Master System Design\n",
      "Master CP\n",
      "GeeksforGeeks Videos\n",
      "Geeks Community\n",
      "Languages\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "PHP\n",
      "GoLang\n",
      "SQL\n",
      "R Language\n",
      "Android Tutorial\n",
      "Tutorials Archive\n",
      "DSA\n",
      "Data Structures\n",
      "Algorithms\n",
      "DSA for Beginners\n",
      "Basic DSA Problems\n",
      "DSA Roadmap\n",
      "Top 100 DSA Interview Problems\n",
      "DSA Roadmap by Sandeep Jain\n",
      "All Cheat Sheets\n",
      "Data Science & ML\n",
      "Data Science With Python\n",
      "Data Science For Beginner\n",
      "Machine Learning Tutorial\n",
      "ML Maths\n",
      "Data Visualisation Tutorial\n",
      "Pandas Tutorial\n",
      "NumPy Tutorial\n",
      "NLP Tutorial\n",
      "Deep Learning Tutorial\n",
      "HTML & CSS\n",
      "HTML\n",
      "CSS\n",
      "Web Templates\n",
      "CSS Frameworks\n",
      "Bootstrap\n",
      "Tailwind CSS\n",
      "SASS\n",
      "LESS\n",
      "Web Design\n",
      "Django Tutorial\n",
      "Python Tutorial\n",
      "Python Programming Examples\n",
      "Python Projects\n",
      "Python Tkinter\n",
      "Web Scraping\n",
      "OpenCV Tutorial\n",
      "Python Interview Question\n",
      "Computer Science\n",
      "Operating Systems\n",
      "Computer Network\n",
      "Database Management System\n",
      "Software Engineering\n",
      "Digital Logic Design\n",
      "Engineering Maths\n",
      "DevOps\n",
      "Git\n",
      "AWS\n",
      "Docker\n",
      "Kubernetes\n",
      "Azure\n",
      "GCP\n",
      "DevOps Roadmap\n",
      "Competitive Programming\n",
      "Top DS or Algo for CP\n",
      "Top 50 Tree\n",
      "Top 50 Graph\n",
      "Top 50 Array\n",
      "Top 50 String\n",
      "Top 50 DP\n",
      "Top 15 Websites for CP\n",
      "System Design\n",
      "High Level Design\n",
      "Low Level Design\n",
      "UML Diagrams\n",
      "Interview Guide\n",
      "Design Patterns\n",
      "OOAD\n",
      "System Design Bootcamp\n",
      "Interview Questions\n",
      "JavaScript\n",
      "JavaScript Examples\n",
      "TypeScript\n",
      "ReactJS\n",
      "NextJS\n",
      "AngularJS\n",
      "NodeJS\n",
      "Lodash\n",
      "Web Browser\n",
      "Preparation Corner\n",
      "Company-Wise Recruitment Process\n",
      "Resume Templates\n",
      "Aptitude Preparation\n",
      "Puzzles\n",
      "Company-Wise Preparation\n",
      "School Subjects\n",
      "Mathematics\n",
      "Physics\n",
      "Chemistry\n",
      "Biology\n",
      "Social Science\n",
      "English Grammar\n",
      "World GK\n",
      "Management & Finance\n",
      "Management\n",
      "HR Management\n",
      "Finance\n",
      "Income Tax\n",
      "Organisational Behaviour\n",
      "Marketing\n",
      "Free Online Tools\n",
      "Typing Test\n",
      "Image Editor\n",
      "Code Formatters\n",
      "Code Converters\n",
      "Currency Converter\n",
      "Random Number Generator\n",
      "Random Password Generator\n",
      "More Tutorials\n",
      "Software Development\n",
      "Software Testing\n",
      "Product Management\n",
      "SAP\n",
      "SEO - Search Engine Optimization\n",
      "Linux\n",
      "Excel\n",
      "GeeksforGeeks Videos\n",
      "DSA\n",
      "Python\n",
      "Java\n",
      "C++\n",
      "Data Science\n",
      "CS Subjects\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited\n",
      ", All rights reserved\n",
      "All rights reserved\n",
      "We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy\n",
      "Got It !\n",
      "We use cookies to ensure you have the best browsing experience on our website. By using our site, you acknowledge that you have read and understood our Cookie Policy & Privacy Policy\n",
      "Cookie Policy\n",
      "Privacy Policy\n",
      "Got It !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def url_browser(url):\n",
    "    chrome_options = Options()\n",
    "    # Uncomment the line below if you want to run Chrome in headless mode\n",
    "    # chrome_options.add_argument(\"--headless\") \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Find all elements containing text\n",
    "    elements = driver.find_elements(By.XPATH,\"//*[text()]\")\n",
    "    \n",
    "    # Iterate through each element and print its text\n",
    "    formatted_text = \"\"\n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        if text:\n",
    "            formatted_text += text + \"\\n\"\n",
    "    \n",
    "    driver.quit()\n",
    "    return formatted_text\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://www.geeksforgeeks.org/video-generation-using-python/\"\n",
    "formatted_text = url_browser(url)\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2ad2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_K",
   "language": "python",
   "name": "openai_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
