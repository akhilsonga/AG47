{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1580dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab2c4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "#code = code\n",
    "\n",
    "def execute_cmd(code):\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        return result.stderr\n",
    "    else:\n",
    "        output = result.stdout\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5596e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = execute_cmd(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d0e6b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID  ...     Sales\n",
      "0          1  ...  261.9600\n",
      "1          2  ...  731.9400\n",
      "2          3  ...   14.6200\n",
      "3          4  ...  957.5775\n",
      "4          5  ...   22.3680\n",
      "...      ...  ...       ...\n",
      "9795    9796  ...    3.7980\n",
      "9796    9797  ...   10.3680\n",
      "9797    9798  ...  235.1880\n",
      "9798    9799  ...   26.3760\n",
      "9799    9800  ...   10.3840\n",
      "\n",
      "[9800 rows x 18 columns]\n",
      "ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d627d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb80f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f1d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BROWSER!\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#URL search-------------------------------------------------------------------------------------------------------\n",
    "def url_browser(url):\n",
    "    print(\"Agent url_browser reporting\")\n",
    "    try:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\") \n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(url)\n",
    "\n",
    "        elements = driver.find_elements(By.XPATH,\"//*[text()]\")\n",
    "        formatted_text = \"\"\n",
    "        for element in elements:\n",
    "            text = element.text.strip()\n",
    "            if text:\n",
    "                formatted_text += text + \"\\n\"\n",
    "\n",
    "        driver.quit()\n",
    "        print(\"Report sent -Over 'url_browser'\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception Occured, may be AI access Denied\",e)\n",
    "        formatted_text = \"Access Denied, Exception occured\"\n",
    "    return formatted_text\n",
    "\n",
    "#Browser search-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def description_filter(text):\n",
    "    lines = text.split('\\n')\n",
    "    source = lines[1]\n",
    "    lines[1] = f'from {source}'\n",
    "    del lines[2]\n",
    "    modified_text = '\\n'.join(lines)\n",
    "    return modified_text\n",
    "\n",
    "def Agent_Browser(search_key):\n",
    "    print(\"Agent_Browser Reporting\")\n",
    "    ordered_urls = OrderedDict()\n",
    "    description_list = []\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    search_text = \"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\"\n",
    "    search_list = \"/html/body/div[5]/div/div[12]/div/div[2]/div[2]/div/div\"\n",
    "\n",
    "    search_text_button = driver.find_element(By.XPATH, search_text)\n",
    "    search_text_button.send_keys(search_key)\n",
    "    search_text_button.send_keys(Keys.ENTER)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    try:\n",
    "        search_list_tag = driver.find_element(By.XPATH, search_list)\n",
    "    except Exception as e:\n",
    "        time.sleep(0.5)\n",
    "        search_list_tag = driver.find_element(By.XPATH, search_list)\n",
    "\n",
    "\n",
    "    child_div_elements = search_list_tag.find_elements(By.XPATH, \"./div\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    for div in child_div_elements:\n",
    "        #description_list.append(div.text)\n",
    "        ref_d = description_filter(div.text)\n",
    "        description_list.append(ref_d)\n",
    "        html_content = div.get_attribute('outerHTML')\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        for child in soup.find_all('div', recursive=True):\n",
    "            for inner_child in child.find_all('div', recursive=True):\n",
    "                for span in inner_child.find_all('span', recursive=True):\n",
    "                    for a_tag in span.find_all('a'):\n",
    "                        href = a_tag.get('href')\n",
    "                        if href:\n",
    "                            if href not in ordered_urls:\n",
    "                                ordered_urls[href] = True\n",
    "    url_dict = dict(ordered_urls)\n",
    "    print(\"Report sent Over! -Agent02\")\n",
    "    return url_dict, description_list\n",
    "#Browser search-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# url_dict, description_list = Agent_Browser(\"python llm code\")\n",
    "\n",
    "# print(\"\\n\\n\\n\")  \n",
    "# print(url_dict)\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a88212e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent_Browser Reporting\n",
      "Report sent Over! -Agent02\n"
     ]
    }
   ],
   "source": [
    "url_dict, description_list = Agent_Browser(\"Github autogen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c0e0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ):   https://github.com/microsoft/autogen\n",
      "( 2 ):   https://microsoft.github.io/autogen/\n",
      "( 3 ):   https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teaching.ipynb\n",
      "( 4 ):   https://microsoft.github.io/autogen/docs/Getting-Started/\n",
      "( 5 ):   https://github.com/microsoft/autogen/releases\n",
      "( 6 ):   https://techcommunity.microsoft.com/t5/educator-developer-blog/autogen-microsoft-s-open-source-tool-for-streamlining/ba-p/4040417#:~:text=AutoGen%20is%20a%20framework%20that,and%20seamlessly%20allow%20human%20participation.\n",
      "( 7 ):   https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb#:~:text=The%20example%20above%20involves%20code,human%20user%20input%20is%20provided.\n",
      "( 8 ):   https://microsoft.github.io/autogen/docs/Getting-Started/#:~:text=With%20customizable%20and%20conversable%20agents,working%20systems%20with%20different%20complexities.\n",
      "( 9 ):   https://www.microsoft.com/en-us/research/project/autogen/#:~:text=AutoGen%20provides%20a%20multi%2Dagent,users%20can%20build%20LLM%20workflows.\n",
      "( 10 ):   https://github.com/topics/autogen\n",
      "( 11 ):   https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb\n",
      "( 12 ):   https://github.com/microsoft/autogen/blob/main/website/docs/Examples.md\n",
      "( 13 ):   https://github.com/microsoft/autogen/issues\n",
      "( 14 ):   https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i in url_dict:\n",
    "    num = num + 1\n",
    "    print(\"(\",num,\"):  \",i)\n",
    "    #print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219c282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa268b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af17d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1a2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import ast #extract print var\n",
    "import subprocess\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24423b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8711ec97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "#count number of tokens\n",
    "def token_count(text):\n",
    "    tokens = text.split()\n",
    "    num_tokens = len(tokens)\n",
    "    return num_tokens\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "#Code print variable analysis\n",
    "\n",
    "class PrintVariableVisitor(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.variables = []\n",
    "\n",
    "    def visit_Call(self, node):\n",
    "        if isinstance(node.func, ast.Name) and node.func.id == 'print':\n",
    "            for arg in node.args:\n",
    "                if isinstance(arg, ast.Name):\n",
    "                    self.variables.append(arg.id)\n",
    "\n",
    "def Print_var(code):\n",
    "# Parse the code into an abstract syntax tree (AST)\n",
    "    tree = ast.parse(code)\n",
    "    # Define a visitor to traverse the AST and extract variables from print statements\n",
    "    # Instantiate the visitor\n",
    "\n",
    "    visitor = PrintVariableVisitor()\n",
    "\n",
    "    # Traverse the AST\n",
    "    visitor.visit(tree)\n",
    "    var = visitor.variables\n",
    "    # Extracted variables\n",
    "    print(\"Variables in print statement:\", var)\n",
    "    return var\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def local_var_list(local_var):\n",
    "    keys = local_var.keys()\n",
    "    keys_list = list(local_var)\n",
    "    keys_list.pop(0)\n",
    "    print(\"-------------------keys_list: \",keys_list)\n",
    "    return keys_list\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def execute_alternative(code):\n",
    "    try:\n",
    "        print(\"Executing CODE: \",code)\n",
    "        local_var = {}\n",
    "        res = exec(code, local_var)\n",
    "        return None, None, local_var  # No return value if code execution succeeds\n",
    "    except FileNotFoundError as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "    except pd.errors.ParserError as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "    except Exception as e:\n",
    "        return None, e, local_var  # Return None for result and the caught exception\n",
    "    \n",
    "def execute(code):\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        return result.stderr\n",
    "    else:\n",
    "        output = result.stdout\n",
    "        return output\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def O_LLM(query):\n",
    "    #\n",
    "    tk_count = token_count(query)\n",
    "    print(\"Query Token Count: \",tk_count)\n",
    "    data = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": query,\n",
    "    \"stream\": False}\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", data=json.dumps(data))\n",
    "    data = json.loads(response.text)\n",
    "    answer = data['response']\n",
    "    print(answer)\n",
    "    return answer\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def Agent07(query):\n",
    "    answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "\n",
    "    code_to_execute = code\n",
    "    #print(\"\\n\\ncode:\",code)\n",
    "    \n",
    "    result = execute(code_to_execute)\n",
    "    return result, code\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_for_error(text):\n",
    "    if 'error' in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame()\n",
    "first_row_csv_string = \"\"\n",
    "\n",
    "def Agent01(inp_query):\n",
    "    \n",
    "    #write a python program to read 'data.csv' and visualize 2 graphs\n",
    "    query = f\"\"\"\n",
    "consider yourself as an Python Data analysis Programmer , where your the best in the world, and has so much self confidence in your code or response.\n",
    "And Now :{inp_query}\n",
    "Always start code with '```python' and end with '```' Your only supposed to give only one python code.\n",
    "Dont add any comments or explanations here, as this will be run in a program, where errors may occur.\"\"\" \n",
    "    #\n",
    "    print(\"\\nQuery: \\n\",query)\n",
    "    result, code = Agent07(query)\n",
    "    \n",
    "    # Example usage:\n",
    "    text_variable = result # \"This is a sample text with an error.\"\n",
    "    if check_for_error(text_variable):\n",
    "        print(\"Code has ERROR\")\n",
    "        result = str(result)\n",
    "        \n",
    "        for i in range(5):\n",
    "            # \n",
    "            print(\"**********ITERATION**************\", i)\n",
    "            code = str(code)\n",
    "            inp_query = str(inp_query)\n",
    "            if i>2:\n",
    "                #\n",
    "                nxt_query = \"\\nUser:\" + inp_query \n",
    "                print(nxt_query)\n",
    "                print(\"i > 2 section\")\n",
    "                result, code = Agent07(nxt_query)\n",
    "            else:\n",
    "                #\n",
    "                nxt_query = \"\\nUser:\" + inp_query + \"\\nBot:\" + code + \"\\nUser: \" + result\n",
    "                print(nxt_query)\n",
    "                print(\"\\n\")\n",
    "                result, code = Agent07(nxt_query)\n",
    "            \n",
    "            \n",
    "            if check_for_error(text_variable):\n",
    "                #\n",
    "                print(text_variable)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"BRAKE APPLIED\")\n",
    "                print(text_variable)\n",
    "                break\n",
    "   \n",
    "                \n",
    "    else:\n",
    "        print(\"Working\")\n",
    "\n",
    "    \n",
    "    \n",
    "#     if error:\n",
    "#         print(\"\\n\\n\")\n",
    "#         print(\"Error:\", error)\n",
    "#         for i in range(5):\n",
    "#             print(\"*****************************************************************************************\")\n",
    "#             #\n",
    "#             print(\"ITERATION: -------------------------0\",i)\n",
    "#             code = str(code)\n",
    "#             error = str(error)\n",
    "#             inp_query = str(inp_query)\n",
    "            \n",
    "#             nxt_query = \"\\nUser:\" + inp_query + \"\\nBot:\" + code + \"\\nUser: Error \" + error\n",
    "#             print(nxt_query)\n",
    "#             print(\"\\n\")\n",
    "#             result, error, code, local_var = Agent07(nxt_query)\n",
    "            \n",
    "            \n",
    "# #             if i == 1:\n",
    "# #                 try:\n",
    "# #                     #\n",
    "# #                     df = local_var[\"df\"]\n",
    "# #                     print(df)\n",
    "\n",
    "# #                     first_row_csv_string = df.iloc[[0]].to_csv(index=False)\n",
    "# #                     print(first_row_csv_string)\n",
    "# #                     first_row_csv_string = str(first_row_csv_string)\n",
    "# #                 except Exception as e:\n",
    "# #                     print(e)\n",
    "\n",
    "            \n",
    "#             try:\n",
    "                \n",
    "#                 if i > 1:\n",
    "#                     var = Print_var(code)\n",
    "#                     if var is None:\n",
    "#                         print(\"var is NONE\")\n",
    "#                         nxt_query = \"/nUser: \"+ inp_query + \"\\n Bot:\" + code + \"\\nUser:\" +\"output: \" + error \n",
    "#                     else:\n",
    "#                         extracted_values = [d[key] for d in local_var if isinstance(d, dict) for key in var if key in d]\n",
    "#                         print(extracted_values)\n",
    "#                         nxt_query = \"/nUser: \"+ inp_query + \"\\n Bot:\" + code + \"\\nUser:\" +\"output: \" + extracted_values + error\n",
    "#                         print(\"oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\")\n",
    "#                         print(\"check extracted values: \",extracted_values)\n",
    "#                         print(\"\\nquery: \\n\\n\")\n",
    "#                         print(nxt_query)\n",
    "                        \n",
    "#                     variable = local_var[var]\n",
    "#                     print(\"++++++++++++++++++++VARIABLE++++++++++++++\", variable)\n",
    "#                     print(type(variable))\n",
    "#                     nxt_query = \"/nUser: \"+ inp_query + \"\\n Bot:\" + code + \"\\nUser:\" +\"output: \"+ variable + \" \\n \" + error \n",
    "#                     print(\"Next Query: \",nxt_query)\n",
    "#                     result, error, code, local_var = Agent07(nxt_query)\n",
    "#                     if result:\n",
    "#                         print(\"result found: \",result)\n",
    "#                         break\n",
    "# #                 else:\n",
    "# #                     nxt_query = \"<user: \"+ inp_query +\">\" + \"\\n\\n\" + \"<bot: \\n\" +\"Code: \" + code + \"\\n\\n Error: \" + error #+ \"\\n\\n 1st row of dataframe df = \" + first_row_csv_string + \" >\"+ \"\\n\\n <Prompt> :By looking at the dataframe, you can change or modify and make the code work, Disclaimer: You need to repond with exact code with no extra comments, code or text, as this will be executed in terminal and may cause errors.\"\n",
    "# #                     result, error, code, local_var = Agent07(nxt_query)\n",
    "# #                     if result:\n",
    "# #                         print(\"result found: \",result)\n",
    "# #                         break\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#     else:\n",
    "#         print(\"\\n\\n\")\n",
    "#         print(\"Result:\", result)\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "def Agent02(inp_query):\n",
    "    \n",
    "    query = f\"\"\" {inp_query}\n",
    "    \n",
    "    By looking at the question do you want to search on internet for better answer the question?\n",
    "    The output should be either 1 for YES, or the actual answer for the query\n",
    "    \"\"\"\n",
    "    print(query)\n",
    "    val = O_LLM(query)\n",
    "    print(val)\n",
    "    print(type(val))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def Agent47():\n",
    "    #inp_query = input(\"Input .>\")\n",
    "    inp_query = \"Python code to read 'D:\\Download\\AKHIL MY Custom Build Agents\\supermarket.csv' and after reading print correlation\"\n",
    "    Data_analysis = Agent01(inp_query)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    Agent47()\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb641a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed296793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seller ID</th>\n",
       "      <th>Seller Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Year Joined</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Language Spoken</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Items Sold</th>\n",
       "      <th>Product Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>81.80</td>\n",
       "      <td>2021-04-17 19:54:08</td>\n",
       "      <td>91</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>67.82</td>\n",
       "      <td>2022-05-09 21:59:46</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>cycle</td>\n",
       "      <td>54.95</td>\n",
       "      <td>2021-08-27 11:50:24</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>bracelets</td>\n",
       "      <td>47.67</td>\n",
       "      <td>2020-11-19 23:00:05</td>\n",
       "      <td>64</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>cycle</td>\n",
       "      <td>61.69</td>\n",
       "      <td>2021-03-09 14:26:53</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>70.54</td>\n",
       "      <td>2020-02-12 15:43:13</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5103d4bd-ad1b-4afc-992c-686a522ec50c</td>\n",
       "      <td>Gregory Padilla</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40580</td>\n",
       "      <td>2011</td>\n",
       "      <td>649.360.8317x794</td>\n",
       "      <td>en</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>17.12</td>\n",
       "      <td>2021-09-16 10:39:57</td>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>15.02</td>\n",
       "      <td>2023-04-30 00:17:38</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>cycle</td>\n",
       "      <td>14.87</td>\n",
       "      <td>2021-07-17 13:05:04</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>cigars</td>\n",
       "      <td>31.96</td>\n",
       "      <td>2023-01-20 07:54:14</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>96.49</td>\n",
       "      <td>2024-03-05 19:27:03</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>78.06</td>\n",
       "      <td>2022-07-18 08:56:04</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>583df991-13cf-4b10-8406-1be8097b38e2</td>\n",
       "      <td>Nathaniel Wells</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33869</td>\n",
       "      <td>2019</td>\n",
       "      <td>(255)325-8523</td>\n",
       "      <td>fr</td>\n",
       "      <td>cigars</td>\n",
       "      <td>89.14</td>\n",
       "      <td>2023-04-08 13:24:09</td>\n",
       "      <td>98</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d334dc80-277b-481d-9c01-ff5295a7d103</td>\n",
       "      <td>William Cohen</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>80528</td>\n",
       "      <td>2022</td>\n",
       "      <td>909-402-4896x805</td>\n",
       "      <td>es</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>8.24</td>\n",
       "      <td>2020-04-19 04:14:52</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d334dc80-277b-481d-9c01-ff5295a7d103</td>\n",
       "      <td>William Cohen</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>80528</td>\n",
       "      <td>2022</td>\n",
       "      <td>909-402-4896x805</td>\n",
       "      <td>es</td>\n",
       "      <td>bracelets</td>\n",
       "      <td>76.64</td>\n",
       "      <td>2022-08-01 14:57:19</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d334dc80-277b-481d-9c01-ff5295a7d103</td>\n",
       "      <td>William Cohen</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>80528</td>\n",
       "      <td>2022</td>\n",
       "      <td>909-402-4896x805</td>\n",
       "      <td>es</td>\n",
       "      <td>flowers</td>\n",
       "      <td>17.91</td>\n",
       "      <td>2022-02-01 16:11:43</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d334dc80-277b-481d-9c01-ff5295a7d103</td>\n",
       "      <td>William Cohen</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>80528</td>\n",
       "      <td>2022</td>\n",
       "      <td>909-402-4896x805</td>\n",
       "      <td>es</td>\n",
       "      <td>cycle</td>\n",
       "      <td>76.14</td>\n",
       "      <td>2021-10-17 09:27:40</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>23.95</td>\n",
       "      <td>2021-04-02 19:59:06</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>bracelets</td>\n",
       "      <td>88.09</td>\n",
       "      <td>2021-10-25 14:24:10</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>cycle</td>\n",
       "      <td>14.04</td>\n",
       "      <td>2021-02-03 03:08:19</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>flowers</td>\n",
       "      <td>24.93</td>\n",
       "      <td>2023-04-17 06:31:48</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>32.82</td>\n",
       "      <td>2023-02-16 19:00:26</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5970d459-787a-4ef6-82ed-b4b0e49bce6a</td>\n",
       "      <td>Raymond Tran</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>46151</td>\n",
       "      <td>2013</td>\n",
       "      <td>+1-310-331-6241x8805</td>\n",
       "      <td>es</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>20.63</td>\n",
       "      <td>2021-09-27 01:36:33</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7ba8cba9-4497-4189-89fa-16be3b18d2da</td>\n",
       "      <td>Garrett Coleman</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>25399</td>\n",
       "      <td>2023</td>\n",
       "      <td>957.479.5803</td>\n",
       "      <td>hi</td>\n",
       "      <td>flowers</td>\n",
       "      <td>99.65</td>\n",
       "      <td>2022-09-30 22:16:55</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7ba8cba9-4497-4189-89fa-16be3b18d2da</td>\n",
       "      <td>Garrett Coleman</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>25399</td>\n",
       "      <td>2023</td>\n",
       "      <td>957.479.5803</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>95.74</td>\n",
       "      <td>2020-06-24 02:28:48</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7ba8cba9-4497-4189-89fa-16be3b18d2da</td>\n",
       "      <td>Garrett Coleman</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>25399</td>\n",
       "      <td>2023</td>\n",
       "      <td>957.479.5803</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>61.52</td>\n",
       "      <td>2022-03-17 00:24:06</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7ba8cba9-4497-4189-89fa-16be3b18d2da</td>\n",
       "      <td>Garrett Coleman</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>25399</td>\n",
       "      <td>2023</td>\n",
       "      <td>957.479.5803</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>57.47</td>\n",
       "      <td>2020-06-11 14:43:42</td>\n",
       "      <td>74</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7ba8cba9-4497-4189-89fa-16be3b18d2da</td>\n",
       "      <td>Garrett Coleman</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>25399</td>\n",
       "      <td>2023</td>\n",
       "      <td>957.479.5803</td>\n",
       "      <td>hi</td>\n",
       "      <td>cigars</td>\n",
       "      <td>72.67</td>\n",
       "      <td>2021-06-29 17:57:49</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ce573904-6d13-4272-a646-4606f68282de</td>\n",
       "      <td>Jennifer Bowers</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>46623</td>\n",
       "      <td>2012</td>\n",
       "      <td>(346)234-6205</td>\n",
       "      <td>es</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>16.52</td>\n",
       "      <td>2023-11-09 22:06:24</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ce573904-6d13-4272-a646-4606f68282de</td>\n",
       "      <td>Jennifer Bowers</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>46623</td>\n",
       "      <td>2012</td>\n",
       "      <td>(346)234-6205</td>\n",
       "      <td>es</td>\n",
       "      <td>cigars</td>\n",
       "      <td>40.98</td>\n",
       "      <td>2021-03-12 01:43:44</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ce573904-6d13-4272-a646-4606f68282de</td>\n",
       "      <td>Jennifer Bowers</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>46623</td>\n",
       "      <td>2012</td>\n",
       "      <td>(346)234-6205</td>\n",
       "      <td>es</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>43.51</td>\n",
       "      <td>2022-11-04 22:19:48</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cec8dc49-fba5-43a8-aef0-e65124fe3a6d</td>\n",
       "      <td>Bryan Sanford</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>10286</td>\n",
       "      <td>2019</td>\n",
       "      <td>001-426-443-4925x765</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>55.56</td>\n",
       "      <td>2023-02-13 14:06:08</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cec8dc49-fba5-43a8-aef0-e65124fe3a6d</td>\n",
       "      <td>Bryan Sanford</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>10286</td>\n",
       "      <td>2019</td>\n",
       "      <td>001-426-443-4925x765</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>52.48</td>\n",
       "      <td>2021-05-02 20:36:41</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cec8dc49-fba5-43a8-aef0-e65124fe3a6d</td>\n",
       "      <td>Bryan Sanford</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>10286</td>\n",
       "      <td>2019</td>\n",
       "      <td>001-426-443-4925x765</td>\n",
       "      <td>hi</td>\n",
       "      <td>handcrafted pots</td>\n",
       "      <td>26.57</td>\n",
       "      <td>2021-10-08 19:41:21</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cec8dc49-fba5-43a8-aef0-e65124fe3a6d</td>\n",
       "      <td>Bryan Sanford</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>10286</td>\n",
       "      <td>2019</td>\n",
       "      <td>001-426-443-4925x765</td>\n",
       "      <td>hi</td>\n",
       "      <td>cycle</td>\n",
       "      <td>41.56</td>\n",
       "      <td>2021-01-10 18:29:35</td>\n",
       "      <td>82</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cec8dc49-fba5-43a8-aef0-e65124fe3a6d</td>\n",
       "      <td>Bryan Sanford</td>\n",
       "      <td>USA</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>10286</td>\n",
       "      <td>2019</td>\n",
       "      <td>001-426-443-4925x765</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>65.43</td>\n",
       "      <td>2020-09-10 07:12:14</td>\n",
       "      <td>27</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>cigars</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2022-07-22 09:01:21</td>\n",
       "      <td>94</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>18.70</td>\n",
       "      <td>2023-01-22 03:14:58</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>65.24</td>\n",
       "      <td>2020-10-21 01:28:50</td>\n",
       "      <td>93</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>flowers</td>\n",
       "      <td>72.31</td>\n",
       "      <td>2020-05-31 13:15:45</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>46.39</td>\n",
       "      <td>2020-12-05 07:25:54</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>tea powder</td>\n",
       "      <td>7.26</td>\n",
       "      <td>2021-12-30 09:59:15</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>e7c35431-1728-4c2e-a83c-792bf3fef3f0</td>\n",
       "      <td>Kelsey Stanley</td>\n",
       "      <td>USA</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>62168</td>\n",
       "      <td>2011</td>\n",
       "      <td>561.866.5895</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>74.03</td>\n",
       "      <td>2021-05-14 08:55:29</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>cigars</td>\n",
       "      <td>26.96</td>\n",
       "      <td>2022-06-23 10:34:08</td>\n",
       "      <td>32</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>20.68</td>\n",
       "      <td>2021-08-06 15:57:01</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>54.64</td>\n",
       "      <td>2023-01-13 14:29:47</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>cycle</td>\n",
       "      <td>11.91</td>\n",
       "      <td>2020-12-04 06:05:54</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>flowers</td>\n",
       "      <td>99.66</td>\n",
       "      <td>2022-02-13 17:30:30</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>flowers</td>\n",
       "      <td>6.86</td>\n",
       "      <td>2021-04-29 16:17:47</td>\n",
       "      <td>41</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fd1c0a85-7902-4b9d-a320-86dba92ce574</td>\n",
       "      <td>Steven Bell</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>62053</td>\n",
       "      <td>2016</td>\n",
       "      <td>+1-856-793-4053x951</td>\n",
       "      <td>en</td>\n",
       "      <td>cigars</td>\n",
       "      <td>26.48</td>\n",
       "      <td>2020-03-19 03:13:43</td>\n",
       "      <td>100</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>cycle</td>\n",
       "      <td>91.21</td>\n",
       "      <td>2020-12-17 15:18:55</td>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>cycle</td>\n",
       "      <td>16.68</td>\n",
       "      <td>2022-05-19 10:34:12</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>flower pot</td>\n",
       "      <td>88.45</td>\n",
       "      <td>2020-03-30 00:54:07</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>bracelets</td>\n",
       "      <td>10.77</td>\n",
       "      <td>2023-01-25 11:17:23</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>cigars</td>\n",
       "      <td>66.02</td>\n",
       "      <td>2022-12-31 15:06:43</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>b067f634-1ded-498c-9120-b3b84fc8918d</td>\n",
       "      <td>Jamie Gonzalez</td>\n",
       "      <td>USA</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20675</td>\n",
       "      <td>2012</td>\n",
       "      <td>967-381-8349</td>\n",
       "      <td>hi</td>\n",
       "      <td>bracelets</td>\n",
       "      <td>17.64</td>\n",
       "      <td>2021-08-21 08:27:47</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Seller ID      Seller Name Country  \\\n",
       "0   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "1   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "2   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "3   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "4   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "5   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "6   5103d4bd-ad1b-4afc-992c-686a522ec50c  Gregory Padilla     USA   \n",
       "7   583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "8   583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "9   583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "10  583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "11  583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "12  583df991-13cf-4b10-8406-1be8097b38e2  Nathaniel Wells     USA   \n",
       "13  d334dc80-277b-481d-9c01-ff5295a7d103    William Cohen     USA   \n",
       "14  d334dc80-277b-481d-9c01-ff5295a7d103    William Cohen     USA   \n",
       "15  d334dc80-277b-481d-9c01-ff5295a7d103    William Cohen     USA   \n",
       "16  d334dc80-277b-481d-9c01-ff5295a7d103    William Cohen     USA   \n",
       "17  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "18  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "19  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "20  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "21  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "22  5970d459-787a-4ef6-82ed-b4b0e49bce6a     Raymond Tran     USA   \n",
       "23  7ba8cba9-4497-4189-89fa-16be3b18d2da  Garrett Coleman     USA   \n",
       "24  7ba8cba9-4497-4189-89fa-16be3b18d2da  Garrett Coleman     USA   \n",
       "25  7ba8cba9-4497-4189-89fa-16be3b18d2da  Garrett Coleman     USA   \n",
       "26  7ba8cba9-4497-4189-89fa-16be3b18d2da  Garrett Coleman     USA   \n",
       "27  7ba8cba9-4497-4189-89fa-16be3b18d2da  Garrett Coleman     USA   \n",
       "28  ce573904-6d13-4272-a646-4606f68282de  Jennifer Bowers     USA   \n",
       "29  ce573904-6d13-4272-a646-4606f68282de  Jennifer Bowers     USA   \n",
       "30  ce573904-6d13-4272-a646-4606f68282de  Jennifer Bowers     USA   \n",
       "31  cec8dc49-fba5-43a8-aef0-e65124fe3a6d    Bryan Sanford     USA   \n",
       "32  cec8dc49-fba5-43a8-aef0-e65124fe3a6d    Bryan Sanford     USA   \n",
       "33  cec8dc49-fba5-43a8-aef0-e65124fe3a6d    Bryan Sanford     USA   \n",
       "34  cec8dc49-fba5-43a8-aef0-e65124fe3a6d    Bryan Sanford     USA   \n",
       "35  cec8dc49-fba5-43a8-aef0-e65124fe3a6d    Bryan Sanford     USA   \n",
       "36  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "37  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "38  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "39  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "40  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "41  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "42  e7c35431-1728-4c2e-a83c-792bf3fef3f0   Kelsey Stanley     USA   \n",
       "43  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "44  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "45  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "46  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "47  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "48  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "49  fd1c0a85-7902-4b9d-a320-86dba92ce574      Steven Bell     USA   \n",
       "50  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "51  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "52  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "53  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "54  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "55  b067f634-1ded-498c-9120-b3b84fc8918d   Jamie Gonzalez     USA   \n",
       "\n",
       "          State Pincode  Year Joined          Phone Number Language Spoken  \\\n",
       "0         Texas   40580         2011      649.360.8317x794              en   \n",
       "1         Texas   40580         2011      649.360.8317x794              en   \n",
       "2         Texas   40580         2011      649.360.8317x794              en   \n",
       "3         Texas   40580         2011      649.360.8317x794              en   \n",
       "4         Texas   40580         2011      649.360.8317x794              en   \n",
       "5         Texas   40580         2011      649.360.8317x794              en   \n",
       "6         Texas   40580         2011      649.360.8317x794              en   \n",
       "7       Alabama   33869         2019         (255)325-8523              fr   \n",
       "8       Alabama   33869         2019         (255)325-8523              fr   \n",
       "9       Alabama   33869         2019         (255)325-8523              fr   \n",
       "10      Alabama   33869         2019         (255)325-8523              fr   \n",
       "11      Alabama   33869         2019         (255)325-8523              fr   \n",
       "12      Alabama   33869         2019         (255)325-8523              fr   \n",
       "13      Wyoming   80528         2022      909-402-4896x805              es   \n",
       "14      Wyoming   80528         2022      909-402-4896x805              es   \n",
       "15      Wyoming   80528         2022      909-402-4896x805              es   \n",
       "16      Wyoming   80528         2022      909-402-4896x805              es   \n",
       "17    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "18    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "19    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "20    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "21    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "22    Louisiana   46151         2013  +1-310-331-6241x8805              es   \n",
       "23     Kentucky   25399         2023          957.479.5803              hi   \n",
       "24     Kentucky   25399         2023          957.479.5803              hi   \n",
       "25     Kentucky   25399         2023          957.479.5803              hi   \n",
       "26     Kentucky   25399         2023          957.479.5803              hi   \n",
       "27     Kentucky   25399         2023          957.479.5803              hi   \n",
       "28   New Jersey   46623         2012         (346)234-6205              es   \n",
       "29   New Jersey   46623         2012         (346)234-6205              es   \n",
       "30   New Jersey   46623         2012         (346)234-6205              es   \n",
       "31  Mississippi   10286         2019  001-426-443-4925x765              hi   \n",
       "32  Mississippi   10286         2019  001-426-443-4925x765              hi   \n",
       "33  Mississippi   10286         2019  001-426-443-4925x765              hi   \n",
       "34  Mississippi   10286         2019  001-426-443-4925x765              hi   \n",
       "35  Mississippi   10286         2019  001-426-443-4925x765              hi   \n",
       "36    Tennessee   62168         2011          561.866.5895              hi   \n",
       "37    Tennessee   62168         2011          561.866.5895              hi   \n",
       "38    Tennessee   62168         2011          561.866.5895              hi   \n",
       "39    Tennessee   62168         2011          561.866.5895              hi   \n",
       "40    Tennessee   62168         2011          561.866.5895              hi   \n",
       "41    Tennessee   62168         2011          561.866.5895              hi   \n",
       "42    Tennessee   62168         2011          561.866.5895              hi   \n",
       "43    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "44    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "45    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "46    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "47    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "48    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "49    Louisiana   62053         2016   +1-856-793-4053x951              en   \n",
       "50    Minnesota   20675         2012          967-381-8349              hi   \n",
       "51    Minnesota   20675         2012          967-381-8349              hi   \n",
       "52    Minnesota   20675         2012          967-381-8349              hi   \n",
       "53    Minnesota   20675         2012          967-381-8349              hi   \n",
       "54    Minnesota   20675         2012          967-381-8349              hi   \n",
       "55    Minnesota   20675         2012          967-381-8349              hi   \n",
       "\n",
       "        Product Name  Price         Date Posted  Items Sold  Product Ranking  \n",
       "0         flower pot  81.80 2021-04-17 19:54:08          91               53  \n",
       "1         tea powder  67.82 2022-05-09 21:59:46          13               53  \n",
       "2              cycle  54.95 2021-08-27 11:50:24          38               53  \n",
       "3          bracelets  47.67 2020-11-19 23:00:05          64               53  \n",
       "4              cycle  61.69 2021-03-09 14:26:53          74               53  \n",
       "5         tea powder  70.54 2020-02-12 15:43:13          41               53  \n",
       "6         flower pot  17.12 2021-09-16 10:39:57          95               53  \n",
       "7   handcrafted pots  15.02 2023-04-30 00:17:38          63               19  \n",
       "8              cycle  14.87 2021-07-17 13:05:04          63               19  \n",
       "9             cigars  31.96 2023-01-20 07:54:14          30               19  \n",
       "10        tea powder  96.49 2024-03-05 19:27:03          58               19  \n",
       "11  handcrafted pots  78.06 2022-07-18 08:56:04           3               19  \n",
       "12            cigars  89.14 2023-04-08 13:24:09          98               19  \n",
       "13  handcrafted pots   8.24 2020-04-19 04:14:52          72                3  \n",
       "14         bracelets  76.64 2022-08-01 14:57:19          77                3  \n",
       "15           flowers  17.91 2022-02-01 16:11:43          59                3  \n",
       "16             cycle  76.14 2021-10-17 09:27:40          93                3  \n",
       "17  handcrafted pots  23.95 2021-04-02 19:59:06          12               22  \n",
       "18         bracelets  88.09 2021-10-25 14:24:10          55               22  \n",
       "19             cycle  14.04 2021-02-03 03:08:19          13               22  \n",
       "20           flowers  24.93 2023-04-17 06:31:48          50               22  \n",
       "21        tea powder  32.82 2023-02-16 19:00:26          66               22  \n",
       "22        flower pot  20.63 2021-09-27 01:36:33          47               22  \n",
       "23           flowers  99.65 2022-09-30 22:16:55          27               34  \n",
       "24        tea powder  95.74 2020-06-24 02:28:48          60               34  \n",
       "25        flower pot  61.52 2022-03-17 00:24:06          66               34  \n",
       "26        flower pot  57.47 2020-06-11 14:43:42          74               34  \n",
       "27            cigars  72.67 2021-06-29 17:57:49          93               34  \n",
       "28        tea powder  16.52 2023-11-09 22:06:24          70               78  \n",
       "29            cigars  40.98 2021-03-12 01:43:44          68               78  \n",
       "30  handcrafted pots  43.51 2022-11-04 22:19:48          28               78  \n",
       "31        tea powder  55.56 2023-02-13 14:06:08          31               61  \n",
       "32        flower pot  52.48 2021-05-02 20:36:41          74               61  \n",
       "33  handcrafted pots  26.57 2021-10-08 19:41:21          32               61  \n",
       "34             cycle  41.56 2021-01-10 18:29:35          82               61  \n",
       "35        tea powder  65.43 2020-09-10 07:12:14          27               61  \n",
       "36            cigars  17.00 2022-07-22 09:01:21          94               32  \n",
       "37        tea powder  18.70 2023-01-22 03:14:58         100               32  \n",
       "38        tea powder  65.24 2020-10-21 01:28:50          93               32  \n",
       "39           flowers  72.31 2020-05-31 13:15:45          32               32  \n",
       "40        flower pot  46.39 2020-12-05 07:25:54          42               32  \n",
       "41        tea powder   7.26 2021-12-30 09:59:15           0               32  \n",
       "42        flower pot  74.03 2021-05-14 08:55:29          38               32  \n",
       "43            cigars  26.96 2022-06-23 10:34:08          32               55  \n",
       "44        flower pot  20.68 2021-08-06 15:57:01          42               55  \n",
       "45        flower pot  54.64 2023-01-13 14:29:47          24               55  \n",
       "46             cycle  11.91 2020-12-04 06:05:54          43               55  \n",
       "47           flowers  99.66 2022-02-13 17:30:30          56               55  \n",
       "48           flowers   6.86 2021-04-29 16:17:47          41               55  \n",
       "49            cigars  26.48 2020-03-19 03:13:43         100               55  \n",
       "50             cycle  91.21 2020-12-17 15:18:55          91               11  \n",
       "51             cycle  16.68 2022-05-19 10:34:12          20               11  \n",
       "52        flower pot  88.45 2020-03-30 00:54:07          10               11  \n",
       "53         bracelets  10.77 2023-01-25 11:17:23          39               11  \n",
       "54            cigars  66.02 2022-12-31 15:06:43          98               11  \n",
       "55         bracelets  17.64 2021-08-21 08:27:47          38               11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "# Initialize Faker to generate fake data\n",
    "fake = Faker()\n",
    "\n",
    "# Function to generate random date\n",
    "def random_date(start_date, end_date):\n",
    "    return start_date + datetime.timedelta(seconds=random.randint(0, int((end_date - start_date).total_seconds())))\n",
    "\n",
    "# Generate random seller data\n",
    "def generate_seller_data(num_sellers):\n",
    "    sellers = []\n",
    "    for _ in range(num_sellers):\n",
    "        seller_id = uuid.uuid4()  # Unique seller ID\n",
    "        seller_name = fake.name()\n",
    "        country = \"USA\"\n",
    "        state = fake.state()\n",
    "        pincode = fake.zipcode()\n",
    "        year_joined = random.randint(2010, 2023)\n",
    "        phone_number = fake.phone_number()\n",
    "        language_spoken = random.choice(['en', 'fr', 'es', 'hi'])  # English, French, Spanish, Hindi\n",
    "        products = []\n",
    "        num_products = random.randint(3, 7)\n",
    "        product_rankings = list(range(1, num_products + 1))\n",
    "        random.shuffle(product_rankings)\n",
    "        for i in range(num_products):\n",
    "            product_name = random.choice(['flower pot', 'bracelets', 'cycle', 'cigars', 'handcrafted pots', 'flowers', 'tea powder'])\n",
    "            date_posted = random_date(datetime.datetime(2020, 1, 1), datetime.datetime.now())\n",
    "            items_sold = random.randint(0, 100)\n",
    "            years_experience = random.randint(1, 10)\n",
    "            price = round(random.uniform(5.0, 100.0), 2)  # Random price between $5 and $100\n",
    "            products.append({\n",
    "                'Product Name': product_name,\n",
    "                'Price': price,\n",
    "                'Date Posted': date_posted,\n",
    "                'Items Sold': items_sold,\n",
    "            })\n",
    "        sellers.append({\n",
    "            'Seller ID': seller_id,\n",
    "            'Seller Name': seller_name,\n",
    "            'Country': country,\n",
    "            'State': state,\n",
    "            'Pincode': pincode,\n",
    "            'Year Joined': year_joined,\n",
    "            'Phone Number': phone_number,\n",
    "            'Language Spoken': language_spoken,\n",
    "            'Products': products\n",
    "        })\n",
    "    return sellers\n",
    "\n",
    "# Generate seller data\n",
    "sellers_data = generate_seller_data(10)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = []\n",
    "product_rankings = list(range(1, 8*10 + 1))  # Total products across all sellers\n",
    "random.shuffle(product_rankings)\n",
    "\n",
    "for seller, rank in zip(sellers_data, product_rankings):\n",
    "    seller_id = seller['Seller ID']\n",
    "    seller_name = seller['Seller Name']\n",
    "    country = seller['Country']\n",
    "    state = seller['State']\n",
    "    pincode = seller['Pincode']\n",
    "    year_joined = seller['Year Joined']\n",
    "    phone_number = seller['Phone Number']\n",
    "    language_spoken = seller['Language Spoken']\n",
    "    for product in seller['Products']:\n",
    "        flattened_data.append({\n",
    "            'Seller ID': seller_id,\n",
    "            'Seller Name': seller_name,\n",
    "            'Country': country,\n",
    "            'State': state,\n",
    "            'Pincode': pincode,\n",
    "            'Year Joined': year_joined,\n",
    "            'Phone Number': phone_number,\n",
    "            'Language Spoken': language_spoken,\n",
    "            'Product Name': product['Product Name'],\n",
    "            'Price': product['Price'],\n",
    "            'Date Posted': product['Date Posted'],\n",
    "            'Items Sold': product['Items Sold'],\n",
    "            'Product Ranking': rank\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd77246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Seller ID', 'Seller Name', 'Country', 'State', 'Pincode',\n",
       "       'Year Joined', 'Phone Number', 'Language Spoken', 'Product Name',\n",
       "       'Price', 'Date Posted', 'Items Sold', 'Product Ranking'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_col = df.columns\n",
    "list_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6904a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c65f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "React_prompt = \"\"\" \n",
    "The 'sales_data.csv' file contains the following columns:\n",
    "['Seller ID', 'Seller Name', 'Country', 'State', 'Pincode','Year Joined', 'Phone Number', 'Language Spoken', 'Product Name','Price', 'Date Posted', 'Items Sold', 'Product Ranking']\n",
    "\n",
    "\n",
    "Thought 1: To create a data visualization, I'll need to decide on the type of chart that would best represent the data. Since we have sales data over time, a line chart showing the trend of sales for each product category could be insightful.\n",
    "\n",
    "Thought 2: I'll use the Matplotlib library to create the line chart. I'll need to group the data by date and category, calculate the total sales for each group, and then plot the results.\n",
    "\n",
    "Thought 3: Here's the code to create the line chart:\n",
    "\n",
    "Action 1: \n",
    "\n",
    "\"\"\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa8b3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To get started with creating a line chart using the given 'sales_data.csv' file and your thoughts, let's first import the required libraries and read the CSV file:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Read the sales data from CSV file into a DataFrame\n",
      "sales_data = pd.read_csv('sales_data.csv')\n",
      "```\n",
      "\n",
      "Now let's proceed with your thoughts:\n",
      "\n",
      "Thought 1 is correct, and you've chosen a suitable chart for displaying sales data over time.\n",
      "\n",
      "Thought 2 is also on the right track, as you'll need to group the data by date and product category, and calculate the total sales for each group before plotting it.\n",
      "\n",
      "Let's implement Thought 2 (Action 1) in code:\n",
      "\n",
      "```python\n",
      "# Group the sales data by date and Product Name, then sum the 'Price' column\n",
      "grouped_data = sales_data.groupby(['Date Posted', 'Product Name'])['Price'].sum().reset_index(name='TotalSales')\n",
      "\n",
      "# Pivot the DataFrame so that each unique combination of Date and ProductName is a column\n",
      "pivot_data = grouped_data.pivot('Date Posted', 'Product Name', 'TotalSales')\n",
      "```\n",
      "\n",
      "Now you have the required data in a pivoted format for creating a line chart using Matplotlib. Next, we'll create and customize the plot:\n",
      "\n",
      "```python\n",
      "# Set up figure and axis objects\n",
      "fig, ax = plt.subplots()\n",
      "\n",
      "# Plot each product's sales against time as separate lines on the same chart\n",
      "for product in pivot_data.columns[1:]:  # Skip the first column (index) for 'Date Posted'\n",
      "    ax.plot(pivot_data.index, pivot_data[product], label=product)\n",
      "\n",
      "# Customize plot appearance\n",
      "ax.legend()\n",
      "ax.set_title('Sales by Product and Date')\n",
      "ax.xlabel('Date')\n",
      "ax.ylabel('Total Sales (INR)')\n",
      "ax.grid(axis='both', which='major', linestyle='-', linewidth='0.5', color='gray')\n",
      "\n",
      "# Display the plot\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "This code will generate a line chart displaying sales trends for each product over time. The x-axis represents dates, and the y-axis shows total sales in Indian Rupees (INR). Each product is represented by a separate line on the chart, making it easy to compare sales trends between different products.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" To get started with creating a line chart using the given 'sales_data.csv' file and your thoughts, let's first import the required libraries and read the CSV file:\\n\\n```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Read the sales data from CSV file into a DataFrame\\nsales_data = pd.read_csv('sales_data.csv')\\n```\\n\\nNow let's proceed with your thoughts:\\n\\nThought 1 is correct, and you've chosen a suitable chart for displaying sales data over time.\\n\\nThought 2 is also on the right track, as you'll need to group the data by date and product category, and calculate the total sales for each group before plotting it.\\n\\nLet's implement Thought 2 (Action 1) in code:\\n\\n```python\\n# Group the sales data by date and Product Name, then sum the 'Price' column\\ngrouped_data = sales_data.groupby(['Date Posted', 'Product Name'])['Price'].sum().reset_index(name='TotalSales')\\n\\n# Pivot the DataFrame so that each unique combination of Date and ProductName is a column\\npivot_data = grouped_data.pivot('Date Posted', 'Product Name', 'TotalSales')\\n```\\n\\nNow you have the required data in a pivoted format for creating a line chart using Matplotlib. Next, we'll create and customize the plot:\\n\\n```python\\n# Set up figure and axis objects\\nfig, ax = plt.subplots()\\n\\n# Plot each product's sales against time as separate lines on the same chart\\nfor product in pivot_data.columns[1:]:  # Skip the first column (index) for 'Date Posted'\\n    ax.plot(pivot_data.index, pivot_data[product], label=product)\\n\\n# Customize plot appearance\\nax.legend()\\nax.set_title('Sales by Product and Date')\\nax.xlabel('Date')\\nax.ylabel('Total Sales (INR)')\\nax.grid(axis='both', which='major', linestyle='-', linewidth='0.5', color='gray')\\n\\n# Display the plot\\nplt.show()\\n```\\n\\nThis code will generate a line chart displaying sales trends for each product over time. The x-axis represents dates, and the y-axis shows total sales in Indian Rupees (INR). Each product is represented by a separate line on the chart, making it easy to compare sales trends between different products.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def O_LLM(query):\n",
    "    #\n",
    "    data = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": query,\n",
    "    \"stream\": False}\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", data=json.dumps(data))\n",
    "    data = json.loads(response.text)\n",
    "    answer = data['response']\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "resp = O_LLM(React_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a21220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c2c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = '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'\n",
    "\n",
    "\n",
    "def O_LLM(query):\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        #model=\"gemma-7b-it\",\n",
    "        temperature = 0,\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e00b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88e137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce4cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15779bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6caa63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Extract_Actions(text):\n",
    "#     #\n",
    "#     thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "#     action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "\n",
    "#     # Extract Thoughts and Actions with numbers\n",
    "#     thoughts = re.findall(thought_pattern, text)\n",
    "#     actions = re.findall(action_pattern, text)\n",
    "\n",
    "#     # Print extracted Thoughts and Actions\n",
    "#     print(\"Extracted Thoughts:\")\n",
    "#     for i, thought in enumerate(thoughts):\n",
    "#         print(f\"Thought {i+1}: {thought}\")\n",
    "\n",
    "#     print(\"\\nExtracted Actions:\")\n",
    "#     for i, action in enumerate(actions):\n",
    "#         print(f\"Action {i+1}: {action}\")\n",
    "        \n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "    output_pattern = r'Output \\d+:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text)\n",
    "    actions = re.findall(action_pattern, text)\n",
    "    outputs = re.findall(output_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "def extract_info(texts):\n",
    "    \"\"\"\n",
    "    This function extracts tools and inputs from a list of text strings.\n",
    "\n",
    "    Args:\n",
    "      texts: A list of strings containing instructions with tools and inputs in brackets.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are tools (e.g., \"Search\", \"Summarize\", \"Calculate\") \n",
    "      and values are corresponding inputs (e.g., \"funding received by Mistral Ai from investors\").\n",
    "    \"\"\"\n",
    "    tools = {}\n",
    "    for text in texts:\n",
    "        # Extract tool using regular expression\n",
    "        tool = re.findall(r'^\\w+', text)[0]\n",
    "\n",
    "        # Extract input using regular expression\n",
    "        inp = re.findall(r'\\[(.*?)\\]', text)[0]\n",
    "\n",
    "        # Add tool and input to the dictionary\n",
    "        tools[tool] = inp\n",
    "    return tools\n",
    "\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "def duck_go(Keyword):\n",
    "    print(Keyword)\n",
    "    results = DDGS().text(Keyword, max_results=5)\n",
    "    bodies = [item['body'] for item in results]\n",
    "    paragraph = ' '.join(bodies)\n",
    "    return paragraph\n",
    "\n",
    "def Calculate(expression):\n",
    "    print(f\"Calculating: {expression}\")\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "def execute_python(code):\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        return result.stderr\n",
    "    else:\n",
    "        output = result.stdout\n",
    "        return output\n",
    "\n",
    "    \n",
    "def code_processing(answer):\n",
    "    #answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "\n",
    "    code_to_execute = code    \n",
    "    result = execute_python(code_to_execute)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def handle_request(data):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        return output\n",
    "    elif \"Calculate\" in data:\n",
    "        output = Calculate(data[\"Calculate\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Calculate\"])\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculate'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "42d122dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating  {'Search': 'funding received by Mistral Ai from investors'}\n",
      "funding received by Mistral Ai from investors\n",
      "Dec. 10, 2023. Mistral AI, a Paris start-up founded seven months ago by researchers from Meta and Google, has raised 385 million euros, or about $415 million, in yet another sign of feverish ... Funding. Mistral AI has raised a total of. 505M. in funding over 5 rounds. Their latest funding was raised on Mar 14, 2024 from a Series A round. Mistral AI is funded by 26 investors. Databricks Ventures and Microsoft are the most recent investors. Unlock for free. retry.school - raised a funding of $99.6K in Seed round held on 01 Mar, 2024. lit.link - raised a funding in Angel round held on 01 Mar, 2024. Mistral AI has raised a total funding of $544M over 3 rounds from 22 investors. Investors include Redpoint Ventures, BNP Paribas and 20 others. Their latest funding round was of $16.3M on Feb 26, 2024 . Listen. 2:19. Mistral AI is in the final stages of raising roughly 450 million ($487 million) from investors including Nvidia Corp. and Salesforce Inc. in a funding round that values the OpenAI ... News. Paris-based startup Mistral AI announced the successful closure of its highly anticipated Series A funding round, raising 385 million (approximately $415 million USD). The funding round, led by Andreessen Horowitz (a16z) with participation from Lightspeed Venture Partners and several other prominent investors, values the company at an ...\n",
      "Full Prompt:  \n",
      "\n",
      "\n",
      "Tools available to use: Search [], Calculate [], Python [], Terminal []\n",
      "Question: Which company building Q* AGI? \n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2 : By understanding Output 1, I need to answer the Question\n",
      "Final Answer: Q* is an AI model developed by OpenAI, as revealed in the information provided. The upheaval and changes at OpenAI, including the removal of the CEO by the chief scientific officer, involved this AI model. Therefore, the company building Q* AGI is OpenAI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question: How much funding did Mistral Ai get from investors?\n",
      "\n",
      "Thought 1: To answer this question, I need to find information about the funding received by Mistral Ai from investors.\n",
      "Action 1: Search [funding received by Mistral Ai from investors]\n",
      "\n",
      "Output 1: \n",
      "\n",
      "\n",
      "output: Dec. 10, 2023. Mistral AI, a Paris start-up founded seven months ago by researchers from Meta and Google, has raised 385 million euros, or about $415 million, in yet another sign of feverish ... Funding. Mistral AI has raised a total of. 505M. in funding over 5 rounds. Their latest funding was raised on Mar 14, 2024 from a Series A round. Mistral AI is funded by 26 investors. Databricks Ventures and Microsoft are the most recent investors. Unlock for free. retry.school - raised a funding of $99.6K in Seed round held on 01 Mar, 2024. lit.link - raised a funding in Angel round held on 01 Mar, 2024. Mistral AI has raised a total funding of $544M over 3 rounds from 22 investors. Investors include Redpoint Ventures, BNP Paribas and 20 others. Their latest funding round was of $16.3M on Feb 26, 2024 . Listen. 2:19. Mistral AI is in the final stages of raising roughly 450 million ($487 million) from investors including Nvidia Corp. and Salesforce Inc. in a funding round that values the OpenAI ... News. Paris-based startup Mistral AI announced the successful closure of its highly anticipated Series A funding round, raising 385 million (approximately $415 million USD). The funding round, led by Andreessen Horowitz (a16z) with participation from Lightspeed Venture Partners and several other prominent investors, values the company at an ...\n",
      "\n",
      "Action 2: By Understanding Output, answer the question\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Based on the information provided, Mistral AI has raised a total of 505M in funding over 5 rounds. Their latest funding was raised on Mar 14, 2024 from a Series A round. Investors include Redpoint Ventures, BNP Paribas and many others. Mistral AI is also in the final stages of raising roughly 450 million ($487 million) from investors including Nvidia Corp. and Salesforce Inc. in a funding round that values the company at a significant amount. Therefore, Mistral Ai has raised a total funding of $544M over 3 rounds from 22 investors.\n"
     ]
    }
   ],
   "source": [
    "One_shot_prompt = \"\"\"\n",
    "Tools available to use: Search [], Calculate [], Python [], Terminal []\n",
    "Question: Which company building Q* AGI? \n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Action 1:Search[company of Q* AGI]\n",
    "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
    "Thought 2 : By understanding Output 1, I need to answer the Question\n",
    "Final Answer: Q* is an AI model developed by OpenAI, as revealed in the information provided. The upheaval and changes at OpenAI, including the removal of the CEO by the chief scientific officer, involved this AI model. Therefore, the company building Q* AGI is OpenAI.\n",
    "\n",
    "\"\"\"\n",
    "New_shot_prompt = \"\"\"\n",
    "\n",
    "Question: How much funding did Mistral Ai get from investors?\n",
    "\n",
    "Thought 1: To answer this question, I need to find information about the funding received by Mistral Ai from investors.\n",
    "Action 1: Search [funding received by Mistral Ai from investors]\n",
    "\n",
    "Output 1: \n",
    "\"\"\"\n",
    "\n",
    "Full_prompt = f\"\"\"\n",
    "{One_shot_prompt}\n",
    "{New_shot_prompt}\n",
    "\"\"\"\n",
    "thoughts, actions, outputs = extract_thoughts_actions_output(New_shot_prompt)\n",
    "\n",
    "extracted_info = extract_info(actions)\n",
    "print(\"Initiating \",extracted_info)\n",
    "\n",
    "tool_out = handle_request(extracted_info)\n",
    "print(tool_out)\n",
    "\n",
    "Full_prompt_ = f\"\"\"\n",
    "{Full_prompt}\n",
    "output: {tool_out}\n",
    "\n",
    "Action 2: By Understanding Output, answer the question\n",
    "\"\"\"\n",
    "print(\"Full Prompt: \",Full_prompt_)\n",
    "\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "resp = O_LLM(Full_prompt_)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "514394d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d007f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating  {}\n",
      "Invalid key. Please use 'Search' or 'Calculate'\n",
      "None\n",
      "Full Prompt:  \n",
      "\n",
      "\n",
      "Tools available to use: Search [], Calculate [], Python [], Terminal []\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2 : By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python [```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "\n",
      "Question: How much funding did Mistral Ai get from investors? And how many letters does the Mistral AI has?\n",
      "Thoughts 1:\n",
      "\n",
      "You should only answer Thought and Action\n",
      "\n",
      "\n",
      "output: None\n",
      "\n",
      "Action 2: By Understanding Output, answer the question\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Thought 1: To answer the question, I need to find out how much funding Mistral AI got from investors.\n",
      "Thought 2: I also need to find out how many letters are in the name \"Mistral AI\".\n",
      "Thought 3: I can use the search tool to find out about Mistral AI's funding.\n",
      "Action 1: Search [Mistral AI funding]\n",
      "\n",
      "(After receiving and processing the search results)\n",
      "\n",
      "Thought 4: Now that I have the funding information, I can proceed to count the number of letters in \"Mistral AI\".\n",
      "Action 2: Python [```python\n",
      "text = \"Mistral AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "\n",
      "(After running the Python code)\n",
      "\n",
      "Final Answer: Mistral AI received funding (<funding amount from the search result>) and it has 9 letters.\n"
     ]
    }
   ],
   "source": [
    "One_shot_prompt = \"\"\"\n",
    "Tools available to use: Search [], Calculate [], Python [], Terminal []\n",
    "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Action 1:Search[company of Q* AGI]\n",
    "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
    "Thought 2 : By understanding Output 1, I need to answer the Question\n",
    "Answer: Q* is an AI model developed by OpenAI.\n",
    "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
    "Action 3: Python [```python\n",
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)\n",
    "```]\n",
    "Output 3: 6\n",
    "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
    "\"\"\"\n",
    "\n",
    "New_shot_prompt = \"\"\"\n",
    "Question: How much funding did Mistral Ai get from investors? And how many letters does the Mistral AI has?\n",
    "Thoughts 1:\n",
    "\n",
    "You should only answer Thought 1 and Action\n",
    "\"\"\"\n",
    "\n",
    "Full_prompt = f\"\"\"\n",
    "{One_shot_prompt}\n",
    "{New_shot_prompt}\n",
    "\"\"\"\n",
    "\n",
    "thoughts, actions, outputs = extract_thoughts_actions_output(New_shot_prompt)\n",
    "\n",
    "extracted_info = extract_info(actions)\n",
    "print(\"Initiating \",extracted_info)\n",
    "\n",
    "tool_out = handle_request(extracted_info)\n",
    "print(tool_out)\n",
    "\n",
    "Full_prompt_ = f\"\"\"\n",
    "{Full_prompt}\n",
    "output: {tool_out}\n",
    "\n",
    "Action 2: By Understanding Output, answer the question\n",
    "\"\"\"\n",
    "print(\"Full Prompt: \",Full_prompt_)\n",
    "\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "resp = O_LLM(Full_prompt_)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0483d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74daa390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "import os\n",
    "from groq import Groq\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = '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'\n",
    "\n",
    "\n",
    "def O_LLM(query):\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        #model=\"gemma-7b-it\",\n",
    "        temperature = 0,\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "    output_pattern = r'Output \\d+:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text)\n",
    "    actions = re.findall(action_pattern, text)\n",
    "    outputs = re.findall(output_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "def extract_info(texts):\n",
    "    \"\"\"\n",
    "    This function extracts tools and inputs from a list of text strings.\n",
    "\n",
    "    Args:\n",
    "      texts: A list of strings containing instructions with tools and inputs in brackets.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are tools (e.g., \"Search\", \"Summarize\", \"Calculate\") \n",
    "      and values are corresponding inputs (e.g., \"funding received by Mistral Ai from investors\").\n",
    "    \"\"\"\n",
    "    tools = {}\n",
    "    for text in texts:\n",
    "        # Extract tool using regular expression\n",
    "        tool = re.findall(r'^\\w+', text)[0]\n",
    "\n",
    "        # Extract input using regular expression\n",
    "        inp = re.findall(r'\\[(.*?)\\]', text)[0]\n",
    "\n",
    "        # Add tool and input to the dictionary\n",
    "        tools[tool] = inp\n",
    "    return tools\n",
    "\n",
    "\n",
    "\n",
    "def duck_go(Keyword):\n",
    "    print(Keyword)\n",
    "    results = DDGS().text(Keyword, max_results=5)\n",
    "    bodies = [item['body'] for item in results]\n",
    "    paragraph = ' '.join(bodies)\n",
    "    return paragraph\n",
    "\n",
    "def Calculate(expression):\n",
    "    print(f\"Calculating: {expression}\")\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "def execute_python(code):\n",
    "    #print(\"Code recieved for execution Terminal: \",code)\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error Found\")\n",
    "        return result.stderr\n",
    "    else:\n",
    "        \n",
    "        output = result.stdout\n",
    "        print(\"output Found: \",output)\n",
    "        return output\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def code_processing(answer):\n",
    "    #answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        #print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            #print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "    print(\"Code Extracted: \",code)\n",
    "    code_to_execute = code    \n",
    "    result = execute_python(code_to_execute)\n",
    "    print(\"Returning Result to Prompt: \", result)\n",
    "    return result\n",
    "\n",
    "def calculate(expression):\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "def handle_request(data):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        param = data[\"Search\"]\n",
    "        prompt = f\"By looking at the context answer this question:{param}\\n Paragrph: {output}\"\n",
    "        output = O_LLM(prompt)\n",
    "        return output\n",
    "    elif \"Calculate\" in data:\n",
    "        output = Calculate(data[\"Calculate\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Python\"])\n",
    "        return output\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculate'\")\n",
    "\n",
    "        \n",
    "def convert_list_to_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        try:\n",
    "            key, value = item.split('[', 1)\n",
    "            value = value.rsplit(']', 1)[0].strip()  # Get text from beginning to last ']'\n",
    "            if value:  # Check if value is not empty (null)\n",
    "                result[key.strip()] = value\n",
    "        except ValueError:\n",
    "            continue  # Skip to the next iteration if splitting fails\n",
    "    return result\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*([\\s\\S]*?)(?=(?:Thought \\d+|$))'\n",
    "    output_pattern = r'output:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text, re.IGNORECASE)\n",
    "    action_matches = re.findall(action_pattern, text, re.IGNORECASE)\n",
    "    actions = ['\\n'.join(action.strip().split('\\n')) for action in action_matches]\n",
    "    outputs = re.findall(output_pattern, text, re.IGNORECASE)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7885e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Example_prompt = \"\"\"\n",
    "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
    "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Action 1:Search[company of Q* AGI]\n",
    "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
    "Thought 2: By understanding Output 1, I need to answer the Question\n",
    "Answer: Q* is an AI model developed by OpenAI.\n",
    "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
    "Action 3: Python[```python\n",
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)\n",
    "```]\n",
    "Output 3: 6\n",
    "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
    "\"\"\"\n",
    "Rules = \"\"\"\n",
    "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
    "Here are the correct syntax to use the tools properly. The value placed inside the tools are only for reference purpose.\n",
    "Search[Open AI all products],\n",
    "\n",
    "Calculate[12+43*45], \n",
    "\n",
    "Python[```python\n",
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)\n",
    "```],\n",
    "\n",
    "Terminal[]\n",
    "\"\"\"\n",
    "\n",
    "question_prompt = \"\"\"\n",
    "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
    "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
    "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Final_answer_check_prompt = \"You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:'\"\n",
    "\n",
    "def Start(Example_prompt, question_prompt):\n",
    "    #\n",
    "    Full_prompt = f\"\"\" {Final_answer_check_prompt} \\n {Example_prompt}\\n_______________________\\n{question_prompt}\"\"\"\n",
    "    #\n",
    "    for i in range(4):\n",
    "        print(\"************************************************************************************************\")\n",
    "        print(Full_prompt)\n",
    "        resp = O_LLM(Full_prompt)\n",
    "        print(resp)\n",
    "        print(\"---------------------------------------------\")\n",
    "        try:\n",
    "            thoughts_list, actions_list, output_list = extract_thoughts_actions_output(resp)\n",
    "            actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "            print(\"All Action tools found: (List) \",actions_tools_dic)\n",
    "\n",
    "            main_dict = actions_tools_dic\n",
    "            last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "\n",
    "            print(\"Last Key value: (Dictionary) \",last_key_value)\n",
    "            result = handle_request(last_key_value)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        #print(result)\n",
    "        num1 = str(i+2)\n",
    "        num2 = str(i+3)\n",
    "        last_element_thoughts_list = thoughts_list[-1]\n",
    "        last_element_actions_list = actions_list[-1]\n",
    "        # Convert the last element to string\n",
    "        last_element_str_thoughts_list = str(last_element_thoughts_list)\n",
    "        last_element_str_actions_list  = str(last_element_actions_list)\n",
    "\n",
    "        #Full_prompt = Example_prompt + question_prompt + resp + \"\\n output: \"+ result #+ \"Though \"+ num +\": \\n\"+ \"Action \"+ num +\": \\n\"\n",
    "        Full_prompt = Full_prompt +\"\\n Thought \"+ num1 + \": \\n\" + last_element_str_thoughts_list +\"\\n Action \"+ num1 + \": \\n\"+ last_element_str_actions_list +\" \" + \"\\noutput: \"+ result + \"\\n Thought \"+ num2 + \": \\n\"+ \"Action \"+ num2 +\": \\n\" + \"Final Answer: \"\n",
    "        \n",
    "        #print(\"FULL UPDATED PROMPT is *__________________________*\\n\\n\\n\\n\",Full_prompt)\n",
    "        inp = input(\"continue?\")\n",
    "        if inp == 'no':\n",
    "            break\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ee1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7a06ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      "Thought 1: First, I need to find out how much funding Mistral AI received from investors.\n",
      "Action 1: Search[Mistral Ai funding]\n",
      "\n",
      "Thought 2: After getting the funding information, I need to multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'Mistral Ai funding'}\n",
      "Last Key value: (Dictionary)  {'Search': 'Mistral Ai funding'}\n",
      "Mistral Ai funding\n",
      "continue?ok\n",
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      " Thought 2: \n",
      "After getting the funding information, I need to multiply the invested amount by 456.\n",
      " Action 2: \n",
      "Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "``` \n",
      "output: Mistral AI, a French startup focused on generative artificial intelligence, has successfully raised 385 million (approximately $415 million) in its Series A funding round, which closed on December 10, 2023. The company was founded seven months ago by researchers from Meta and Google and has been valued at around $2 billion after the funding round. This funding indicates strong investor confidence and will support the company's expansion and development plans. Mistral AI aims to become a leading European player in the generative AI field, leveraging its open and responsible approach. Its release of foundational models, such as Mistral 7B and Mixtral 8x7B, has garnered significant attention.\n",
      " Thought 3: \n",
      "Action 3: \n",
      "Final Answer: \n",
      "Thought 1: First, I need to find out how much funding Mistral AI got from investors.\n",
      "Action 1: Search[funding of Mistral AI]\n",
      "\n",
      "Thought 2: After getting the funding information, I need to multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'funding of Mistral AI'}\n",
      "Last Key value: (Dictionary)  {'Search': 'funding of Mistral AI'}\n",
      "funding of Mistral AI\n",
      "continue?no\n"
     ]
    }
   ],
   "source": [
    "resp = Start(Example_prompt, question_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a1a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca92f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b370b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351ec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a163a61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      "Thought 1: First, I need to find out how much funding Mistral AI received from investors.\n",
      "Action 1: Search[Mistral Ai funding]\n",
      "\n",
      "Thought 2: After getting the funding information, I need to multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'Mistral Ai funding'}\n",
      "Last Key value: (Dictionary)  {'Search': 'Mistral Ai funding'}\n",
      "Mistral Ai funding\n",
      "continue?ok\n",
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      " Thought 2: \n",
      "After getting the funding information, I need to multiply the invested amount by 456.\n",
      " Action 2: \n",
      "Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "``` \n",
      "output: Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round. The company was founded four weeks ago by researchers from Meta and Google and has been valued at around 2 billion dollars. This funding round indicates strong investor confidence in Mistral AI, providing significant financial resources for potential expansion and development.\n",
      " Thought 3: \n",
      "Action 3: \n",
      "Final Answer: \n",
      "Thought 1: First, I need to find out how much funding Mistral AI received from investors.\n",
      "Action 1: Search[funding of Mistral AI]\n",
      "\n",
      "(After receiving the funding information)\n",
      "\n",
      "Thought 2: Now that I have the funding information, I can multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "funding = 415_000_000  # Replace this number with the funding from Search output\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456.\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'funding of Mistral AI'}\n",
      "Last Key value: (Dictionary)  {'Search': 'funding of Mistral AI'}\n",
      "funding of Mistral AI\n",
      "continue?ok\n",
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      " Thought 2: \n",
      "After getting the funding information, I need to multiply the invested amount by 456.\n",
      " Action 2: \n",
      "Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "``` \n",
      "output: Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round. The company was founded four weeks ago by researchers from Meta and Google and has been valued at around 2 billion dollars. This funding round indicates strong investor confidence in Mistral AI, providing significant financial resources for potential expansion and development.\n",
      " Thought 3: \n",
      "Action 3: \n",
      "Final Answer: \n",
      " Thought 3: \n",
      "Now that I have the funding information, I can multiply the invested amount by 456.\n",
      " Action 3: \n",
      "Python[]\n",
      "```python\n",
      "funding = 415_000_000  # Replace this number with the funding from Search output\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456. \n",
      "output: The funding of Mistral AI was closed through a Series A round, where the company raised 385 million (approximately $415 million) according to a Dec. 10, 2023 report. This funding round has made Mistral AI valued at around 2 billion (about $2 billion), which indicates strong investor confidence and provides the financial resources for potential expansion and development. The company, founded just seven months ago by researchers from Meta and Google, has announced the successful raise of $415 million, with a portion of this amount coming from a seed funding round.\n",
      " Thought 4: \n",
      "Action 4: \n",
      "Final Answer: \n",
      "Thought 1: I need to find out how much funding Mistral AI got from investors.\n",
      "Action 1: Search[funding of Mistral AI]\n",
      "\n",
      "Thought 2: After getting the funding information, I need to multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Thought 3 (in case the output doesn't provide a specific number):\n",
      "I need to extract the exact funding amount from the search output to perform the calculation.\n",
      "Action 3: Python[]\n",
      "```python\n",
      "search_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\n",
      "funding = float(search_output.split(\"raised \")[-1].split(\",\")[0])\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456.\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'funding of Mistral AI', 'Python': ']\\n```python\\nsearch_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\\nfunding = float(search_output.split(\"raised \")[-1].split(\",\")[0'}\n",
      "Last Key value: (Dictionary)  {'Python': ']\\n```python\\nsearch_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\\nfunding = float(search_output.split(\"raised \")[-1].split(\",\")[0'}\n",
      "\n",
      "\n",
      "\n",
      "Code Extracted:  ]\n",
      "```python\n",
      "search_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\n",
      "funding = float(search_output.split(\"raised \")[-1].split(\",\")[0\n",
      "Error Found\n",
      "Returning Result to Prompt:    File \"<string>\", line 1\n",
      "    ]\n",
      "    ^\n",
      "SyntaxError: unmatched ']'\n",
      "\n",
      "continue?ok\n",
      "************************************************************************************************\n",
      " You should not add any additional comments to Actions or Thoughts. Check If you have all the information and are capable of answering the question, Answer the question under 'Final Answer:' \n",
      " \n",
      "Tools available to use: Search[], Calculate[], Python[], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "_______________________\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: How much funding did Mistral Ai get from investors? And multiple the invested amount of mistral AI to 456 in Python\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action.\n",
      "\n",
      "\n",
      " Thought 2: \n",
      "After getting the funding information, I need to multiply the invested amount by 456.\n",
      " Action 2: \n",
      "Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "``` \n",
      "output: Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round. The company was founded four weeks ago by researchers from Meta and Google and has been valued at around 2 billion dollars. This funding round indicates strong investor confidence in Mistral AI, providing significant financial resources for potential expansion and development.\n",
      " Thought 3: \n",
      "Action 3: \n",
      "Final Answer: \n",
      " Thought 3: \n",
      "Now that I have the funding information, I can multiply the invested amount by 456.\n",
      " Action 3: \n",
      "Python[]\n",
      "```python\n",
      "funding = 415_000_000  # Replace this number with the funding from Search output\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456. \n",
      "output: The funding of Mistral AI was closed through a Series A round, where the company raised 385 million (approximately $415 million) according to a Dec. 10, 2023 report. This funding round has made Mistral AI valued at around 2 billion (about $2 billion), which indicates strong investor confidence and provides the financial resources for potential expansion and development. The company, founded just seven months ago by researchers from Meta and Google, has announced the successful raise of $415 million, with a portion of this amount coming from a seed funding round.\n",
      " Thought 4: \n",
      "Action 4: \n",
      "Final Answer: \n",
      " Thought 4: \n",
      "After getting the funding information, I need to multiply the invested amount by 456.\n",
      " Action 4: \n",
      "Python[]\n",
      "```python\n",
      "search_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\n",
      "funding = float(search_output.split(\"raised \")[-1].split(\",\")[0])\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456. \n",
      "output:   File \"<string>\", line 1\n",
      "    ]\n",
      "    ^\n",
      "SyntaxError: unmatched ']'\n",
      "\n",
      " Thought 5: \n",
      "Action 5: \n",
      "Final Answer: \n",
      "Thought 1: I need to find out how much funding Mistral Ai received from investors.\n",
      "Action 1: Search[funding of Mistral Ai]\n",
      "\n",
      "Thought 2: After getting the funding information, I need to multiply the invested amount by 456.\n",
      "Action 2: Python[]\n",
      "```python\n",
      "# Funding input from Search\n",
      "funding = ...\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "\n",
      "Thought 3: Now that I have the funding information, I can multiply the invested amount by 456.\n",
      "Action 3: Python[]\n",
      "```python\n",
      "search_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\n",
      "funding = float(search_output.split(\"raised \")[-1].split(\",\")[0])\n",
      "result = funding * 456\n",
      "print(result)\n",
      "```\n",
      "Final Answer: The output of the Python code will provide the result after multiplying the funding by 456.\n",
      "---------------------------------------------\n",
      "All Action tools found: (List)  {'Search': 'funding of Mistral Ai', 'Python': ']\\n```python\\nsearch_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\\nfunding = float(search_output.split(\"raised \")[-1].split(\",\")[0'}\n",
      "Last Key value: (Dictionary)  {'Python': ']\\n```python\\nsearch_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\\nfunding = float(search_output.split(\"raised \")[-1].split(\",\")[0'}\n",
      "\n",
      "\n",
      "\n",
      "Code Extracted:  ]\n",
      "```python\n",
      "search_output = \"Mistral AI, a French artificial intelligence start-up, has raised 385 million euros, or about 415 million dollars, in a Series A funding round.\"\n",
      "funding = float(search_output.split(\"raised \")[-1].split(\",\")[0\n",
      "Error Found\n",
      "Returning Result to Prompt:    File \"<string>\", line 1\n",
      "    ]\n",
      "    ^\n",
      "SyntaxError: unmatched ']'\n",
      "\n",
      "continue?no\n"
     ]
    }
   ],
   "source": [
    "Full_prompt = f\"\"\" {Final_answer_check_prompt} \\n {Example_prompt}\\n_______________________\\n{question_prompt}\"\"\"\n",
    "for i in range(4):\n",
    "    print(\"************************************************************************************************\")\n",
    "    print(Full_prompt)\n",
    "    resp = O_LLM(Full_prompt)\n",
    "    print(resp)\n",
    "    print(\"---------------------------------------------\")\n",
    "    try:\n",
    "        thoughts_list, actions_list, output_list = extract_thoughts_actions_output(resp)\n",
    "        actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "        print(\"All Action tools found: (List) \",actions_tools_dic)\n",
    "\n",
    "        main_dict = actions_tools_dic\n",
    "        last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "\n",
    "        print(\"Last Key value: (Dictionary) \",last_key_value)\n",
    "        result = handle_request(last_key_value)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    #print(result)\n",
    "    num1 = str(i+2)\n",
    "    num2 = str(i+3)\n",
    "    last_element_thoughts_list = thoughts_list[-1]\n",
    "    last_element_actions_list = actions_list[-1]\n",
    "    # Convert the last element to string\n",
    "    last_element_str_thoughts_list = str(last_element_thoughts_list)\n",
    "    last_element_str_actions_list  = str(last_element_actions_list)\n",
    "\n",
    "    #Full_prompt = Example_prompt + question_prompt + resp + \"\\n output: \"+ result #+ \"Though \"+ num +\": \\n\"+ \"Action \"+ num +\": \\n\"\n",
    "    Full_prompt = Full_prompt +\"\\n Thought \"+ num1 + \": \\n\" + last_element_str_thoughts_list +\"\\n Action \"+ num1 + \": \\n\"+ last_element_str_actions_list +\" \" + \"\\noutput: \"+ result + \"\\n Thought \"+ num2 + \": \\n\"+ \"Action \"+ num2 +\": \\n\" + \"Final Answer: \"\n",
    "\n",
    "    #print(\"FULL UPDATED PROMPT is *__________________________*\\n\\n\\n\\n\",Full_prompt)\n",
    "    inp = input(\"continue?\")\n",
    "    if inp == 'no':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e2665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d66c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "import os\n",
    "from groq import Groq\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = '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'\n",
    "\n",
    "\n",
    "def O_LLM(query):\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        #model=\"gemma-7b-it\",\n",
    "        temperature = 0,\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "    output_pattern = r'Output \\d+:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text)\n",
    "    actions = re.findall(action_pattern, text)\n",
    "    outputs = re.findall(output_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "def extract_info(texts):\n",
    "    \"\"\"\n",
    "    This function extracts tools and inputs from a list of text strings.\n",
    "\n",
    "    Args:\n",
    "      texts: A list of strings containing instructions with tools and inputs in brackets.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are tools (e.g., \"Search\", \"Summarize\", \"Calculate\") \n",
    "      and values are corresponding inputs (e.g., \"funding received by Mistral Ai from investors\").\n",
    "    \"\"\"\n",
    "    tools = {}\n",
    "    for text in texts:\n",
    "        # Extract tool using regular expression\n",
    "        tool = re.findall(r'^\\w+', text)[0]\n",
    "\n",
    "        # Extract input using regular expression\n",
    "        inp = re.findall(r'\\[(.*?)\\]', text)[0]\n",
    "\n",
    "        # Add tool and input to the dictionary\n",
    "        tools[tool] = inp\n",
    "    return tools\n",
    "\n",
    "\n",
    "\n",
    "def duck_go(Keyword):\n",
    "    print(Keyword)\n",
    "    results = DDGS().text(Keyword, max_results=5)\n",
    "    bodies = [item['body'] for item in results]\n",
    "    paragraph = ' '.join(bodies)\n",
    "    return paragraph\n",
    "\n",
    "def Calculate(expression):\n",
    "    print(f\"Calculating: {expression}\")\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "def execute_python(code):\n",
    "    #print(\"Code recieved for execution Terminal: \",code)\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error Found\")\n",
    "        return result.stderr\n",
    "    else:\n",
    "        \n",
    "        output = result.stdout\n",
    "        print(\"output Found: \",output)\n",
    "        return output\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def code_processing(answer):\n",
    "    #answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        #print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            #print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "    print(\"Code Extracted: \",code)\n",
    "    code_to_execute = code    \n",
    "    result = execute_python(code_to_execute)\n",
    "    print(\"Returning Result to Prompt: \", result)\n",
    "    return result\n",
    "\n",
    "def Calculate(expression):\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "def handle_request(data):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        param = data[\"Search\"]\n",
    "        prompt = f\"By looking at the context answer this question:{param}\\n Paragrph: {output}\"\n",
    "        output = O_LLM(prompt)\n",
    "        return output\n",
    "    elif \"Calculate\" in data:\n",
    "        output = Calculate(data[\"Calculate\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Python\"])\n",
    "        return output\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculate'\")\n",
    "\n",
    "        \n",
    "def convert_list_to_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        try:\n",
    "            key, value = item.split('[', 1)\n",
    "            value = value.rsplit(']', 1)[0].strip()  # Get text from beginning to last ']'\n",
    "            if value:  # Check if value is not empty (null)\n",
    "                result[key.strip()] = value\n",
    "        except ValueError:\n",
    "            continue  # Skip to the next iteration if splitting fails\n",
    "    return result\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*([\\s\\S]*?)(?=(?:Thought \\d+|$))'\n",
    "    output_pattern = r'output:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text, re.IGNORECASE)\n",
    "    action_matches = re.findall(action_pattern, text, re.IGNORECASE)\n",
    "    actions = ['\\n'.join(action.strip().split('\\n')) for action in action_matches]\n",
    "    outputs = re.findall(output_pattern, text, re.IGNORECASE)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee1fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d1f720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tools available to use: Search[], Calculate[], Python[Runs python code in terminal], Terminal[]\n",
      "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Answer: Q* is an AI model developed by OpenAI.\n",
      "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 3: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Output 3: 6\n",
      "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
      "\n",
      "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
      "Question: Search how many jobs posted in a day and In python, check how many tokens are there in the search?\n",
      "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action at this time.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Example_prompt = \"\"\"\n",
    "Tools available to use: Search[], Calculate[], Python[Runs python code in terminal], Terminal[]\n",
    "Question: Which company building Q* AGI? And check how many letters does that company name have?\n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Action 1:Search[company of Q* AGI]\n",
    "Output 1: In the aftermath of last month's upheaval at OpenAI, attention has turned to the enigmatic Q*a groundbreaking AI model that played a central role in the removal of CEO Sam Altman by the company's chief scientific officer, Ilya Sutskever, and its board.\n",
    "Thought 2: By understanding Output 1, I need to answer the Question\n",
    "Answer: Q* is an AI model developed by OpenAI.\n",
    "Thought 3: Write a python code to check how many does 'OpenAI' have?\n",
    "Action 3: Python[```python\n",
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)\n",
    "```]\n",
    "Output 3: 6\n",
    "Final Answer: Q* is an AI model developed by OpenAI, And it has 6 letters\n",
    "\"\"\"\n",
    "\n",
    "question_prompt = \"\"\"\n",
    "Write your Thought and Action for this question. And you are not allowed to write the Output at all.Always use the tools as per the syntax showned above example.\n",
    "Question: Search how many jobs posted in a day and In python, check how many tokens are there in the search?\n",
    "Break down the Question into multiple simple Thoughts and Actions with numbers increasing order. Your only able to write one Thought and action at this time.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Final_answer_check_prompt = Example_prompt + question_prompt\n",
    "print(Final_answer_check_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54453c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ChatGPT: \n",
      "Thought 1: First I need to search how many jobs are posted in a day.\n",
      "Action 1: Search[\"number of jobs posted in a day\"]\n",
      "All Action tools found: (List)  {'Search': '\"number of jobs posted in a day\"'}\n",
      "\"number of jobs posted in a day\"\n",
      "Output:  In order to provide you with an answer, I would need the actual paragraph that the phrase \"number of jobs posted in a day\" is found in. The phrase itself refers to the total count of job openings that are advertised or listed as available in a 24-hour period. However, without more context, it is difficult to provide a more specific or accurate answer.\n",
      "\n",
      "If you could provide the paragraph or even a larger section of text, I would be better able to understand the topic and give you a more precise response. Thank you for your understanding.\n",
      "\n",
      " ChatGPT: \n",
      "I'm unable to provide responses directly from the provided output. If you can provide the context or paragraph where the term \"number of jobs posted in a day\" is mentioned, I can help you analyze it further. Just share the relevant text or additional context to proceed with the analysis.\n",
      "All Action tools found: (List)  {}\n",
      "Invalid key. Please use 'Search' or 'Calculate'\n",
      "Output:  None\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "messages = [ {\"role\": \"system\", \"content\":  \n",
    "              \"You are a intelligent assistant.\"} ] \n",
    "Run = True\n",
    "\n",
    "message = Final_answer_check_prompt\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    if message: \n",
    "        messages.append( \n",
    "            {\"role\": \"user\", \"content\": message}, \n",
    "        ) \n",
    "        chat = openai.ChatCompletion.create( \n",
    "            model=\"gpt-3.5-turbo\", messages=messages \n",
    "        ) \n",
    "    resp = chat.choices[0].message.content \n",
    "    print(f\"\\n ChatGPT: \\n{resp}\") \n",
    "    messages.append({\"role\": \"assistant\", \"content\": resp}) \n",
    "    \n",
    "    thoughts_list, actions_list, output_list = extract_thoughts_actions_output(resp)\n",
    "    actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "    print(\"All Action tools found: (List) \",actions_tools_dic)\n",
    "    result = handle_request(actions_tools_dic)\n",
    "    print(\"Output: \",result)\n",
    "    if result is None:\n",
    "        break\n",
    "    else:\n",
    "        message = \"Output: \" + str(result)\n",
    "    \n",
    "#     messages.append({\"role\": \"assistant\", \"Output\": result}) \n",
    "\n",
    "# h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab312ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14b91aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In calculate value passing is:  415 million * 456\n",
      "415 million * 456\n",
      "Output:  Error: invalid syntax (<string>, line 1)\n"
     ]
    }
   ],
   "source": [
    "actions_tools_dic = {'Calculator': '415 million * 456'}\n",
    "\n",
    "result = handle_request(actions_tools_dic)\n",
    "print(\"Output: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fd6da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculator(expression):\n",
    "    try:\n",
    "        print(expression)\n",
    "        result = eval(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "def handle_request(data):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        param = data[\"Search\"]\n",
    "        prompt = f\"By looking at the context answer this question:{param}\\n Paragrph: {output}\"\n",
    "        output = O_LLM(prompt)\n",
    "        return output\n",
    "    elif \"Calculator\" in data:\n",
    "        print(\"In calculate value passing is: \", data[\"Calculator\"])\n",
    "        output = Calculate(data[\"Calculator\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Python\"])\n",
    "        return output\n",
    " \n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculator'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647ba96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af014780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230280"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invested_amount = 505\n",
    "multiplied_value = invested_amount * 456\n",
    "multiplied_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d516b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c43837da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion:\n",
      "\n",
      "Sure, I can help you with that! Here's some sample Python code that uses the `llama-index` library to read a PDF file and create a vector database for a Retriever-Generator (RAG) model using the Hugging Face `datasets` library.\n",
      "\n",
      "First, you need to install the required libraries. You can install them using pip:\n",
      "```\n",
      "pip install llama-index datasets transformers\n",
      "```\n",
      "Here's the code:\n",
      "```python\n",
      "import os\n",
      "import sys\n",
      "from typing import List, Tuple\n",
      "\n",
      "import datasets\n",
      "import numpy as np\n",
      "import torch\n",
      "from llama_index import SimpleDocument, GPTSimpleVectorIndex, GPTSimpleVectorIndexReader, GPTSimpleVectorIndexWriter, SimpleDirectoryReader\n",
      "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
      "\n",
      "# Set device\n",
      "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "\n",
      "# Load PDF file\n",
      "pdf_path = \"path/to/your/pdf/file.pdf\"\n",
      "documents = SimpleDirectoryReader(pdf_path).load_data()\n",
      "\n",
      "# Tokenize documents\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
      "tokenized_documents = tokenizer([doc.text for doc in documents], padding=True, truncation=True, return_tensors=\"pt\")\n",
      "\n",
      "# Create vector index\n",
      "vector_index = GPTSimpleVectorIndex(tokenized_documents, documents, device=device)\n",
      "\n",
      "# Save vector index\n",
      "vector_index_path = \"path/to/save/vector/index\"\n",
      "os.makedirs(vector_index_path, exist_ok=True)\n",
      "vector_index_writer = GPTSimpleVectorIndexWriter(vector_index)\n",
      "vector_index_writer.save(vector_index_path)\n",
      "\n",
      "# Load vector index reader\n",
      "vector_index_reader = GPTSimpleVectorIndexReader(vector_index_path, device=device)\n",
      "\n",
      "# Create RAG model\n",
      "rag_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/rag-token-base\")\n",
      "rag_tokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
      "\n",
      "# Create RAG dataset\n",
      "rag_dataset = datasets.load_dataset(\"json\", data_files=[\"path/to/your/json/file.json\"])[\"data\"]\n",
      "rag_dataset = rag_dataset.map(lambda x: {\"question\": x[\"question\"], \"context\": x[\"context\"]}, batched=True)\n",
      "\n",
      "# Create RAG generator\n",
      "rag_generator = datasets.RAGGenerator(rag_model, rag_tokenizer, vector_index_reader, num_beams=4, max_length=50, early_stopping=True)\n",
      "\n",
      "# Generate answers\n",
      "for example in rag_dataset:\n",
      "    question = example[\"question\"]\n",
      "    input_dict = rag_tokenizer(question, return_tensors=\"pt\")\n",
      "    input_dict[\"context\"] = example[\"context\"]\n",
      "    generated_answer = rag_generator.generate(**input_dict)\n",
      "    print(f\"Question: {question}\")\n",
      "    print(f\"Generated answer: {generated_answer[0]['generated_text']}\")\n",
      "```\n",
      "In this code, you need to replace `path/to/your/pdf/file.pdf` with the path to your PDF file, and `path/to/save/vector/index` with the path where you want to save the vector index. You also need to replace `path/to/your/json/file.json` with the path to your JSON file containing the questions and contexts for the RAG model to generate answers for.\n",
      "\n",
      "The code first loads the PDF file using `SimpleDirectoryReader` and tokenizes the documents using the BERT tokenizer. It then creates a vector index using `GPTSimpleVectorIndex` and saves it to disk using `GPTSimpleVectorIndexWriter`.\n",
      "\n",
      "Next, the code loads the vector index reader using `GPTSimpleVectorIndexReader` and creates a RAG model and tokenizer using the Hugging Face `transformers` library. It then creates a RAG dataset by loading a JSON file containing questions and contexts, and maps it to a format that can be used by the RAG generator.\n",
      "\n",
      "Finally, the code creates a RAG generator using the RAG model, tokenizer, and vector index reader, and generates answers for each question in the RAG dataset.\n",
      "\n",
      "I hope this helps! Let me know if you have any questions or need further assistance.\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# In this section, we set the user authentication, user and app ID, model details, and the URL of \n",
    "# the text we want as an input. Change these strings to run your own example.\n",
    "######################################################################################################\n",
    "\n",
    "# Your PAT (Personal Access Token) can be found in the portal under Authentification\n",
    "PAT = '53323b6483bf4571895458c609fb47c9'\n",
    "# Specify the correct user_id/app_id pairings\n",
    "# Since you're making inferences outside your app's scope\n",
    "USER_ID = 'databricks'\n",
    "APP_ID = 'drbx'\n",
    "# Change these to whatever model and text URL you want to use\n",
    "MODEL_ID = 'dbrx-instruct'\n",
    "MODEL_VERSION_ID = 'fd96af0170e34d4ca56f1d120f8ee9d9'\n",
    "RAW_TEXT = 'Python code to read pdf from llama-index and create vector DB RAG'\n",
    "# To use a hosted text file, assign the url variable\n",
    "# TEXT_FILE_URL = 'https://samples.clarifai.com/negative_sentence_12.txt'\n",
    "# Or, to use a local text file, assign the url variable\n",
    "# TEXT_FILE_LOCATION = 'YOUR_TEXT_FILE_LOCATION_HERE'\n",
    "\n",
    "############################################################################\n",
    "# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n",
    "############################################################################\n",
    "\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "\n",
    "channel = ClarifaiChannel.get_grpc_channel()\n",
    "stub = service_pb2_grpc.V2Stub(channel)\n",
    "\n",
    "metadata = (('authorization', 'Key ' + PAT),)\n",
    "\n",
    "userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n",
    "\n",
    "# To use a local text file, uncomment the following lines\n",
    "# with open(TEXT_FILE_LOCATION, \"rb\") as f:\n",
    "#    file_bytes = f.read()\n",
    "\n",
    "post_model_outputs_response = stub.PostModelOutputs(\n",
    "    service_pb2.PostModelOutputsRequest(\n",
    "        user_app_id=userDataObject,  # The userDataObject is created in the overview and is required when using a PAT\n",
    "        model_id=MODEL_ID,\n",
    "        version_id=MODEL_VERSION_ID,  # This is optional. Defaults to the latest model version\n",
    "        inputs=[\n",
    "            resources_pb2.Input(\n",
    "                data=resources_pb2.Data(\n",
    "                    text=resources_pb2.Text(\n",
    "                        raw=RAW_TEXT\n",
    "                        # url=TEXT_FILE_URL\n",
    "                        # raw=file_bytes\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    metadata=metadata\n",
    ")\n",
    "if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "    print(post_model_outputs_response.status)\n",
    "    raise Exception(f\"Post model outputs failed, status: {post_model_outputs_response.status.description}\")\n",
    "\n",
    "# Since we have one input, one output will exist here\n",
    "output = post_model_outputs_response.outputs[0]\n",
    "\n",
    "print(\"Completion:\\n\")\n",
    "print(output.data.text.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18c74e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clarifai_grpc\n",
      "  Downloading clarifai_grpc-10.2.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: grpcio>=1.44.0 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from clarifai_grpc) (1.62.1)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from clarifai_grpc) (4.25.3)\n",
      "Collecting googleapis-common-protos>=1.53.0 (from clarifai_grpc)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from clarifai_grpc) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akhil\\anaconda3\\envs\\openai_langchain\\lib\\site-packages (from requests>=2.25.1->clarifai_grpc) (2024.2.2)\n",
      "Downloading clarifai_grpc-10.2.3-py3-none-any.whl (237 kB)\n",
      "   ---------------------------------------- 0.0/237.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/237.9 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/237.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 237.9/237.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 229.1/229.1 kB ? eta 0:00:00\n",
      "Installing collected packages: googleapis-common-protos, clarifai_grpc\n",
      "Successfully installed clarifai_grpc-10.2.3 googleapis-common-protos-1.63.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install clarifai_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe4eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec81f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5395ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ecc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57aab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import curses\n",
    "\n",
    "s = curses.initscr()\n",
    "curses.curs_set(0)\n",
    "sh, sw = s.getmaxyx()\n",
    "w = curses.newwin(sh, sw, 0, 0)\n",
    "w.keypad(1)\n",
    "w.timeout(100)\n",
    "\n",
    "snk_x = sw//4\n",
    "snk_y = sh//2\n",
    "snake = [\n",
    "    [snk_y, snk_x],\n",
    "    [snk_y, snk_x-1],\n",
    "    [snk_y, snk_x-2]\n",
    "]\n",
    "\n",
    "food = [sh//2, sw//2]\n",
    "w.addch(int(food[0]), int(food[1]), curses.ACS_PI)\n",
    "\n",
    "key = curses.KEY_RIGHT\n",
    "\n",
    "while True:\n",
    "    next_key = w.getch()\n",
    "    key = key if next_key == -1 else next_key\n",
    "\n",
    "    if snake[0][0] in [0, sh] or \\\n",
    "        snake[0][1]  in [0, sw] or \\\n",
    "        snake[0] in snake[1:]:\n",
    "        curses.endwin()\n",
    "        quit()\n",
    "\n",
    "    new_head = [snake[0][0], snake[0][1]]\n",
    "\n",
    "    if key == curses.KEY_DOWN:\n",
    "        new_head[0] += 1\n",
    "    if key == curses.KEY_UP:\n",
    "        new_head[0] -= 1\n",
    "    if key == curses.KEY_LEFT:\n",
    "        new_head[1] -= 1\n",
    "    if key == curses.KEY_RIGHT:\n",
    "        new_head[1] += 1\n",
    "\n",
    "    snake.insert(0, new_head)\n",
    "\n",
    "    if snake[0] == food:\n",
    "        food = None\n",
    "        while food is None:\n",
    "            nf = [\n",
    "                random.randint(1, sh-1),\n",
    "                random.randint(1, sw-1)\n",
    "            ]\n",
    "            food = nf if nf not in snake else None\n",
    "        w.addch(food[0], food[1], curses.ACS_PI)\n",
    "    else:\n",
    "        tail = snake.pop()\n",
    "        w.addch(int(tail[0]), int(tail[1]), ' ')\n",
    "\n",
    "    w.addch(int(snake[0][0]), int(snake[0][1]), curses.ACS_CKBOARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa7cf591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting windows-curses\n",
      "  Downloading windows_curses-2.3.2-cp39-cp39-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading windows_curses-2.3.2-cp39-cp39-win_amd64.whl (89 kB)\n",
      "   ---------------------------------------- 0.0/89.1 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/89.1 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 41.0/89.1 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 89.1/89.1 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: windows-curses\n",
      "Successfully installed windows-curses-2.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install windows-curses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac0f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd81e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580aaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "from langdetect import detect\n",
    "from pytube import YouTube\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "def startfile(fn):\n",
    "    os.system('open %s' % fn)\n",
    "\n",
    "def create_and_open_txt(text, filename):\n",
    "    # Create and write the text to a txt file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(text)\n",
    "    startfile(filename)\n",
    "\n",
    "#url = \"https://www.youtube.com/watch?v=62gpF6Uq6Rc\" #input(\"Enter the YouTube video URL: \")\n",
    "\n",
    "def youtube_audio_text(url):\n",
    "    yt = YouTube(url)\n",
    "\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "\n",
    "    output_path = r\"C:\\Users\\akhil\\Downloads\\YoutubeAudios\"\n",
    "    filename = \"audio.mp3\"\n",
    "    audio_stream.download(output_path=output_path, filename=filename)\n",
    "\n",
    "    print(f\"Audio downloaded to {output_path}/{filename}\")\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(\"C:\\\\Users\\\\akhil\\\\Downloads\\\\YoutubeAudios\\\\audio.mp3\")\n",
    "    transcribed_text = result[\"text\"]\n",
    "    print(transcribed_text)\n",
    "\n",
    "    language = detect(transcribed_text)\n",
    "    print(f\"Detected language: {language}\")\n",
    "\n",
    "    create_and_open_txt(transcribed_text, f\"C:\\\\Users\\\\akhil\\\\Downloads\\\\YoutubeAudios\\\\output_Text_{language}.txt\")\n",
    "\n",
    "\n",
    "def Youtube_RAG(model):\n",
    "    llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "    inp = input(\"enter 1 - Hugging Face Embedding \\n2 - OpenAI Embedding\")\n",
    "    inp = int(inp)\n",
    "    if inp == 1:\n",
    "        #\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=\"flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\")\n",
    "    else:\n",
    "        #\n",
    "        embed_model = OpenAIEmbedding(embed_batch_size=10)\n",
    "        Settings.embed_model = embed_model\n",
    "\n",
    "\n",
    "    #Settings.llm = Ollama(model=\"mistral\", request_timeout=200.0)\n",
    "    Settings.llm = Ollama(model=model, request_timeout=200.0)\n",
    "    \n",
    "    documents = SimpleDirectoryReader(r\"C:\\Users\\akhil\\Downloads\\YoutubeAudios\").load_data()\n",
    "    sen_split=TokenTextSplitter()\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[sen_split]\n",
    "    )\n",
    "    nodes=pipeline.run(show_progress=True,documents=documents, in_place=True)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, transformations=[sen_split]\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=\"./indexDB\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./indexDB\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"Summary of the Document\")\n",
    "    print(response)\n",
    "    for i in range(10):\n",
    "        #\n",
    "        que = input(\"Question\")\n",
    "        que = que.lower()\n",
    "        if que = \"exit\":\n",
    "            break\n",
    "        response = query_engine.query(que)\n",
    "        print(response)\n",
    "        \n",
    "\n",
    "def youtube():\n",
    "    url = input(\"Enter the YouTube video URL: \")\n",
    "    youtube_audio_text(url)\n",
    "    model_id = input(\"Enter the model you want to use: 1 - Mistral, 2- Codellama 13B, 3 - llava\")\n",
    "    if model_id == 1:\n",
    "        Youtube_RAG(\"mistral\")\n",
    "    elif model_id == 2:\n",
    "        Youtube_RAG(\"codellama:13b\")\n",
    "#     elif model_id == 3:\n",
    "#         Youtube_RAG(\"codellama:13b\")\n",
    "\n",
    "\n",
    "youtube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd22689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: C:\\Users\\akhil\\Downloads\\YoutubeAudios : The process cannot access the file because it is being used by another process\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\akhil\\\\Downloads\\\\YoutubeAudios'\n",
    "\n",
    "# Check if the folder exists\n",
    "if os.path.exists(folder_path):\n",
    "    try:\n",
    "        # Delete the folder and its contents\n",
    "        os.rmdir(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {folder_path} : {e.strerror}\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b8dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e34396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "from langdetect import detect\n",
    "from pytube import YouTube\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "def startfile(fn):\n",
    "    os.system('open %s' % fn)\n",
    "\n",
    "def create_and_open_txt(text, filename):\n",
    "    # Create and write the text to a txt file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(text)\n",
    "    startfile(filename)\n",
    "\n",
    "\n",
    "def delete_audio_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Audio file {file_path} deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting audio file: {e}\")\n",
    "\n",
    "    \n",
    "def youtube_audio_text(url, path):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    \n",
    "    output_path = path #r\"C:\\Users\\akhil\\Downloads\\YoutubeAudios\"\n",
    "    filename = \"audio.mp3\"\n",
    "    audio_stream.download(output_path=output_path, filename=filename)\n",
    "\n",
    "    print(f\"Audio downloaded to {output_path}/{filename}\")\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(path + \"\\audio.mp3\")\n",
    "    transcribed_text = result[\"text\"]\n",
    "    print(transcribed_text)\n",
    "\n",
    "    language = detect(transcribed_text)\n",
    "    print(f\"Detected language: {language}\")\n",
    "    delete_audio_file(path + \"\\audio.mp3\")\n",
    "    \n",
    "    create_and_open_txt(transcribed_text, path + \"\\output_Text_{language}.txt\")\n",
    "\n",
    "\n",
    "def Youtube_RAG(model):\n",
    "    llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "    inp = input(\"enter 1 - Hugging Face Embedding \\n2 - OpenAI Embedding\")\n",
    "    inp = int(inp)\n",
    "    if inp == 1:\n",
    "        #\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=\"flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\")\n",
    "    else:\n",
    "        #\n",
    "        embed_model = OpenAIEmbedding(embed_batch_size=10)\n",
    "        Settings.embed_model = embed_model\n",
    "\n",
    "    #Settings.llm = Ollama(model=\"mistral\", request_timeout=200.0)\n",
    "    Settings.llm = Ollama(model=model, request_timeout=200.0)\n",
    "    \n",
    "    documents = SimpleDirectoryReader(path).load_data()\n",
    "    sen_split=TokenTextSplitter()\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[sen_split]\n",
    "    )\n",
    "    nodes=pipeline.run(show_progress=True,documents=documents, in_place=True)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, transformations=[sen_split]\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=\"./indexDB\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./indexDB\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"Summary of the Document\")\n",
    "    print(response)\n",
    "    for i in range(20):\n",
    "        #\n",
    "        que = input(\"Question\")\n",
    "        que = que.lower()\n",
    "        if que = \"exit\" or \"bye\":\n",
    "            break\n",
    "        response = query_engine.query(que)\n",
    "        print(response)\n",
    "        \n",
    "\n",
    "def youtube():\n",
    "    url = input(\"Enter the YouTube video URL: \")\n",
    "    youtube_audio_text(url, \"C:\\Users\\akhil\\Downloads\\YOUTUBE_VIDEO_SCRPT_WRITTER\\New folder\")\n",
    "    model_id = input(\"Enter the model you want to use: 1 - Mistral, 2- Codellama 13B, 3 - llava\")\n",
    "    if model_id == 1:\n",
    "        Youtube_RAG(\"mistral\")\n",
    "    elif model_id == 2:\n",
    "        Youtube_RAG(\"codellama:13b\")\n",
    "#     elif model_id == 3:\n",
    "#         Youtube_RAG(\"codellama:13b\")\n",
    "\n",
    "\n",
    "youtube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb10bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ed0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321b5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae8790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25f10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c45717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Postal Code     Sales\n",
      "Postal Code     1.000000 -0.024067\n",
      "Sales          -0.024067  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with all data types\n",
    "df = pd.read_csv('D:/Download/AKHIL MY Custom Build Agents/supermarket.csv', dtype=None)\n",
    "\n",
    "# Select only the numeric columns\n",
    "num_cols = df.select_dtypes(include='float64')\n",
    "corr_matrix = num_cols.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48abe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af390f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309299f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd58b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba11db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca82aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb00bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81143394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e69f6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 21]\n"
     ]
    }
   ],
   "source": [
    "extracted_values = [d[key] for d in local_var if isinstance(d, dict) for key in ('a', 'ab') if key in d]\n",
    "\n",
    "print(extracted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18039298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61af13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508a453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb774862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83bbfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response from LLM\n",
    "\n",
    "def O_LLM(query):\n",
    "    #\n",
    "    data = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": query,\n",
    "    \"stream\": False}\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", data=json.dumps(data))\n",
    "    data = json.loads(response.text)\n",
    "    answer = data['response']\n",
    "    print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa23d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve code from response\n",
    "\n",
    "def Agent07(query):\n",
    "    answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "\n",
    "    code_to_execute = code\n",
    "    print(\"\\n\\ncode:\",code)\n",
    "    \n",
    "    result, error, local_var = execute(code_to_execute)\n",
    "    \n",
    "    print(\"\\n \\nEXECUTION OUTPUT:\")\n",
    "    if error:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Error:\", error)\n",
    "    else:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Result:\", result)\n",
    "        \n",
    "    return result, error, code, local_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66fca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6810baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \" \"\n",
    "\n",
    "def Controller():\n",
    "    print(\"Lets The Game Begin\")\n",
    "    prompt_to_do_list = \"Give me devika AI research paper analysis \"\n",
    "#     query_to_do_list = f\"\"\"\n",
    "# Consider yourself as a Main function in the python code, you can call multiple functions, by considering the user query,\n",
    "# you have to choose which functions, and what sequence should it run?\n",
    "# Functions list:  Internet_Search() , Summarize() , Python_Code_Executor()\n",
    "# Disclaimer: You dont need to use all functions, Do not add any comments, extra code, or other opinion, rather than just functions to use.\n",
    "# User: search internet about 'devika AI' and give me report analyis\n",
    "# Bot:\n",
    "# 1) Internet_Search()\n",
    "# 2) Summarize()\n",
    "\n",
    "# User: {prompt_to_do_list}\n",
    "#     \"\"\"\n",
    "    \n",
    "    \n",
    "    query_to_do_list = f\"\"\"\n",
    "Consider yourself as a Human, who is proficient in software, AI, Report analysis, To do list expert. \n",
    "Now taking this input, give me consize to do list by using only with these tools.\n",
    "Tools: 1) Search Internet(enter a keyword, I will search and return that content from internet)\n",
    "2) Python Executor(Execute python code directly here)\n",
    "3) Summarize(Summarize the text)\n",
    "Disclaimer: Do not add any comments, code, or other opinion, rather than just tools to use.\n",
    "Example:\n",
    "User: Give me Qstar research paper analysis\n",
    "Bot: 1) Use 'Search' Tool and keyword 'Qstar research paper'\n",
    "2) Use 'Summarize' tool \n",
    "\n",
    "User:\n",
    "    {prompt_to_do_list}\n",
    "    \"\"\"\n",
    "        \n",
    "    print(query_to_do_list)\n",
    "    answer = O_LLM(query_to_do_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0f34c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets The Game Begin\n",
      "\n",
      "Consider yourself as a Main function in the python code, you can call multiple functions, by considering the user query,\n",
      "you have to choose which functions, and what sequence should it run?\n",
      "Functions list:  Internet_Search() , Summarize() , Python_Code_Executor()\n",
      "Disclaimer: You dont need to use all functions, Do not add any comments, extra code, or other opinion, rather than just functions to use.\n",
      "User: search internet about 'devika AI' and give me report analyis\n",
      "Bot:\n",
      "1) Internet_Search()\n",
      "2) Summarize()\n",
      "\n",
      "User: Give me devika AI research paper analysis \n",
      "    \n",
      " Bot:\n",
      "1) Internet\\_Search('devika AI research paper')\n",
      "2) Summarize()\n",
      "3) Python\\_Code\\_Executor(summarized\\_data\\_from\\_internet\\_search\\_function, 'process\\_research\\_paper.py')\n",
      "\n",
      "Note: In the last step, you may assume there is a Python script named 'process\\_research\\_paper.py' to handle the analysis of research papers.\n",
      " Bot:\n",
      "1) Internet\\_Search('devika AI research paper')\n",
      "2) Summarize()\n",
      "3) Python\\_Code\\_Executor(summarized\\_data\\_from\\_internet\\_search\\_function, 'process\\_research\\_paper.py')\n",
      "\n",
      "Note: In the last step, you may assume there is a Python script named 'process\\_research\\_paper.py' to handle the analysis of research papers.\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    answer = Controller()\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7d3d2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Bot:\\n1) Internet\\\\_Search('devika AI research paper')\\n2) Summarize()\\n3) Python\\\\_Code\\\\_Executor(summarized\\\\_data\\\\_from\\\\_Internet\\\\_Search\\\\_function, 'extract\\\\_research\\\\_papers.py')\\n\\nThis sequence will first search the internet for information about 'devika AI research papers', then summarize the findings, and lastly execute the python script 'extract\\\\_research\\\\_papers.py' to analyze the summarized data.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e1275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bca7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8a1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    query_to_do_list = f\"\"\"\n",
    "Consider yourself as a Human, who is proficient in software, AI, Report analysis, To do list expert. \n",
    "Now taking this input, give me consize to do list by using only with these tools.\n",
    "Tools: 1) Search Internet(enter a keyword, I will search and return that content from internet)\n",
    "2) Python Executor(Execute python code directly here)\n",
    "3) Summarize(Summarize the text)\n",
    "Disclaimer: Do not add any comments, code, or other opinion, rather than just tools to use.\n",
    "Example:\n",
    "User: Give me Qstar research paper analysis\n",
    "Bot: 1) Use Search Tool and keyword 'Qstar research paper'\n",
    "2) Use Summarize tool \n",
    "\n",
    "\n",
    "Now answer\n",
    "    {prompt_to_do_list}\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_K",
   "language": "python",
   "name": "openai_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
